//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31442593
// Cuda compilation tools, release 11.7, V11.7.99
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_61
.address_size 64

	// .globl	K4

.visible .entry K4(
	.param .u64 K4_param_0,
	.param .u64 K4_param_1,
	.param .u64 K4_param_2,
	.param .u64 K4_param_3,
	.param .u64 K4_param_4,
	.param .u64 K4_param_5,
	.param .u64 K4_param_6,
	.param .u64 K4_param_7,
	.param .u64 K4_param_8,
	.param .u64 K4_param_9,
	.param .u64 K4_param_10,
	.param .u64 K4_param_11,
	.param .u64 K4_param_12
)
{
	.reg .pred 	%p<33>;
	.reg .f32 	%f<62>;
	.reg .b32 	%r<21>;
	.reg .f64 	%fd<8>;
	.reg .b64 	%rd<206>;
	.loc	1 2 0


	ld.param.u64 	%rd67, [K4_param_0];
	ld.param.u64 	%rd57, [K4_param_1];
	ld.param.u64 	%rd68, [K4_param_2];
	ld.param.u64 	%rd69, [K4_param_3];
	ld.param.u64 	%rd58, [K4_param_4];
	ld.param.u64 	%rd59, [K4_param_5];
	ld.param.u64 	%rd60, [K4_param_6];
	ld.param.u64 	%rd61, [K4_param_7];
	ld.param.u64 	%rd62, [K4_param_8];
	ld.param.u64 	%rd63, [K4_param_9];
	ld.param.u64 	%rd64, [K4_param_10];
	ld.param.u64 	%rd65, [K4_param_11];
	ld.param.u64 	%rd66, [K4_param_12];
	.loc	1 11 26
	cvta.to.global.u64 	%rd1, %rd69;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd68;
	mov.u32 	%r3, %tid.x;
	cvt.u64.u32 	%rd4, %r3;
	and.b64  	%rd70, %rd65, -4294967296;
	setp.eq.s64 	%p1, %rd70, 0;
	@%p1 bra 	$L__BB0_2;

	.loc	1 0 26
	div.s64 	%rd199, %rd4, %rd65;
	bra.uni 	$L__BB0_3;

$L__BB0_2:
	cvt.u32.u64 	%r4, %rd65;
	cvt.u32.u64 	%r5, %rd4;
	div.u32 	%r6, %r5, %r4;
	cvt.u64.u32 	%rd199, %r6;

$L__BB0_3:
	.loc	1 11 26
	mov.u32 	%r7, %ctaid.x;
	cvt.u64.u32 	%rd71, %r7;
	mul.lo.s64 	%rd72, %rd71, %rd66;
	add.s64 	%rd8, %rd199, %rd72;
	.loc	1 12 5
	setp.ge.s64 	%p2, %rd8, %rd62;
	@%p2 bra 	$L__BB0_31;

	.loc	1 13 32
	mul.lo.s64 	%rd9, %rd64, %rd63;
	.loc	1 14 27
	shl.b64 	%rd75, %rd8, 2;
	add.s64 	%rd73, %rd59, %rd75;
	.loc	1 14 29
	.loc	2 124 107, function_name $L__info_string0, inlined_at 1 14 29
	// begin inline asm
	ld.global.nc.u32 %r8, [%rd73];
	// end inline asm
	.loc	1 14 29
	cvt.u64.u32 	%rd10, %r8;
	.loc	1 15 27
	add.s64 	%rd74, %rd73, 4;
	.loc	1 15 29
	.loc	2 124 107, function_name $L__info_string0, inlined_at 1 15 29
	// begin inline asm
	ld.global.nc.u32 %r9, [%rd74];
	// end inline asm
	.loc	1 15 29
	cvt.u64.u32 	%rd11, %r9;
	@%p1 bra 	$L__BB0_6;

	.loc	1 0 29
	rem.s64 	%rd201, %rd4, %rd65;
	bra.uni 	$L__BB0_7;

$L__BB0_6:
	cvt.u32.u64 	%r10, %rd65;
	cvt.u32.u64 	%r11, %rd4;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd201, %r12;

$L__BB0_7:
	.loc	1 17 9
	setp.ge.s64 	%p4, %rd201, %rd9;
	@%p4 bra 	$L__BB0_31;

	.loc	1 0 9
	cvt.u32.u64 	%r1, %rd11;
	cvt.u32.u64 	%r2, %rd10;
	.loc	1 17 29
	mov.u32 	%r13, %ntid.x;
	cvt.u64.u32 	%rd16, %r13;
	shl.b64 	%rd17, %rd8, 32;
	.loc	1 20 13
	not.b64 	%rd77, %rd10;
	add.s64 	%rd18, %rd77, %rd11;
	sub.s64 	%rd78, %rd11, %rd10;
	and.b64  	%rd19, %rd78, 3;
	shl.b64 	%rd79, %rd10, 3;
	add.s64 	%rd21, %rd61, %rd79;
	add.s64 	%rd22, %rd21, 8;
	add.s64 	%rd23, %rd60, %rd79;
	add.s64 	%rd24, %rd23, 8;
	add.s64 	%rd26, %rd21, 16;
	add.s64 	%rd27, %rd23, 16;
	add.s64 	%rd28, %rd10, 3;
	.loc	1 11 26
	cvta.to.global.u64 	%rd29, %rd58;
	cvta.to.global.u64 	%rd30, %rd57;
	setp.ge.u32 	%p5, %r2, %r1;
	mov.f32 	%f18, 0f00000000;
	setp.eq.s64 	%p6, %rd19, 0;
	setp.lt.u64 	%p18, %rd18, 3;
	setp.eq.s64 	%p10, %rd19, 1;

$L__BB0_9:
	.loc	1 20 13
	mov.f32 	%f57, %f18;
	@%p5 bra 	$L__BB0_30;

	.loc	1 27 17
	mov.u64 	%rd202, %rd10;
	mov.f32 	%f57, %f18;
	@%p6 bra 	$L__BB0_19;

	.loc	1 0 17
	shl.b64 	%rd189, %rd10, 3;
	add.s64 	%rd188, %rd60, %rd189;
	add.s64 	%rd187, %rd61, %rd189;
	.loc	1 21 40
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	// begin inline asm
	ld.global.nc.u64 %rd80, [%rd187];
	// end inline asm
	.loc	1 22 37
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	// begin inline asm
	ld.global.nc.f64 %fd1, [%rd188];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd34, %fd1;
	.loc	1 25 40
	cvt.u32.u64 	%r14, %rd80;
	.loc	1 27 17
	setp.eq.s32 	%p7, %r14, -1;
	setp.eq.s64 	%p8, %rd34, 0;
	mov.f32 	%f57, 0f00000000;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB0_13;

	.loc	1 19 76
	shr.u64 	%rd194, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd83, %rd80, %rd17;
	.loc	1 28 43
	add.s64 	%rd84, %rd83, %rd194;
	.loc	1 28 86
	shl.b64 	%rd85, %rd83, 5;
	add.s64 	%rd86, %rd85, %rd201;
	.loc	1 31 35
	shl.b64 	%rd87, %rd84, 2;
	add.s64 	%rd88, %rd3, %rd87;
	shl.b64 	%rd89, %rd86, 2;
	add.s64 	%rd90, %rd2, %rd89;
	ld.global.f32 	%f22, [%rd90];
	ld.global.f32 	%f23, [%rd88];
	mul.f32 	%f24, %f23, %f22;
	.loc	1 28 127
	add.s64 	%rd91, %rd34, %rd194;
	.loc	1 34 35
	shl.b64 	%rd92, %rd91, 2;
	add.s64 	%rd93, %rd1, %rd92;
	ld.global.f32 	%f25, [%rd93];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f24, %f25, 0f00000000;

$L__BB0_13:
	.loc	1 0 21
	add.s64 	%rd202, %rd10, 1;
	.loc	1 20 13
	@%p10 bra 	$L__BB0_19;

	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	// begin inline asm
	ld.global.nc.u64 %rd94, [%rd22];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	// begin inline asm
	ld.global.nc.f64 %fd2, [%rd24];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd36, %fd2;
	.loc	1 25 40
	cvt.u32.u64 	%r15, %rd94;
	.loc	1 27 17
	setp.eq.s32 	%p11, %r15, -1;
	setp.eq.s64 	%p12, %rd36, 0;
	or.pred  	%p13, %p11, %p12;
	@%p13 bra 	$L__BB0_16;

	.loc	1 19 76
	shr.u64 	%rd193, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd97, %rd94, %rd17;
	.loc	1 28 43
	add.s64 	%rd98, %rd97, %rd193;
	.loc	1 28 86
	shl.b64 	%rd99, %rd97, 5;
	add.s64 	%rd100, %rd99, %rd201;
	.loc	1 31 35
	shl.b64 	%rd101, %rd98, 2;
	add.s64 	%rd102, %rd3, %rd101;
	shl.b64 	%rd103, %rd100, 2;
	add.s64 	%rd104, %rd2, %rd103;
	ld.global.f32 	%f26, [%rd104];
	ld.global.f32 	%f27, [%rd102];
	mul.f32 	%f28, %f27, %f26;
	.loc	1 28 127
	add.s64 	%rd105, %rd36, %rd193;
	.loc	1 34 35
	shl.b64 	%rd106, %rd105, 2;
	add.s64 	%rd107, %rd1, %rd106;
	ld.global.f32 	%f29, [%rd107];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f28, %f29, %f57;

$L__BB0_16:
	.loc	1 0 21
	add.s64 	%rd202, %rd10, 2;
	setp.eq.s64 	%p14, %rd19, 2;
	.loc	1 20 13
	@%p14 bra 	$L__BB0_19;

	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	// begin inline asm
	ld.global.nc.u64 %rd108, [%rd26];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	// begin inline asm
	ld.global.nc.f64 %fd3, [%rd27];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd38, %fd3;
	.loc	1 25 40
	cvt.u32.u64 	%r16, %rd108;
	.loc	1 27 17
	setp.eq.s32 	%p15, %r16, -1;
	setp.eq.s64 	%p16, %rd38, 0;
	or.pred  	%p17, %p15, %p16;
	mov.u64 	%rd202, %rd28;
	@%p17 bra 	$L__BB0_19;

	.loc	1 19 76
	shr.u64 	%rd192, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd111, %rd108, %rd17;
	.loc	1 28 43
	add.s64 	%rd112, %rd111, %rd192;
	.loc	1 28 86
	shl.b64 	%rd113, %rd111, 5;
	add.s64 	%rd114, %rd113, %rd201;
	.loc	1 31 35
	shl.b64 	%rd115, %rd112, 2;
	add.s64 	%rd116, %rd3, %rd115;
	shl.b64 	%rd117, %rd114, 2;
	add.s64 	%rd118, %rd2, %rd117;
	ld.global.f32 	%f30, [%rd118];
	ld.global.f32 	%f31, [%rd116];
	mul.f32 	%f32, %f31, %f30;
	.loc	1 28 127
	add.s64 	%rd119, %rd38, %rd192;
	.loc	1 34 35
	shl.b64 	%rd120, %rd119, 2;
	add.s64 	%rd121, %rd1, %rd120;
	ld.global.f32 	%f33, [%rd121];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f32, %f33, %f57;
	mov.u64 	%rd202, %rd28;

$L__BB0_19:
	.loc	1 27 17
	@%p18 bra 	$L__BB0_30;

	shl.b64 	%rd122, %rd202, 3;
	add.s64 	%rd204, %rd61, %rd122;
	add.s64 	%rd205, %rd60, %rd122;

$L__BB0_21:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	// begin inline asm
	ld.global.nc.u64 %rd123, [%rd204];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	// begin inline asm
	ld.global.nc.f64 %fd4, [%rd205];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd46, %fd4;
	.loc	1 25 40
	cvt.u32.u64 	%r17, %rd123;
	.loc	1 27 17
	setp.eq.s32 	%p19, %r17, -1;
	setp.eq.s64 	%p20, %rd46, 0;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB0_23;

	.loc	1 19 76
	shr.u64 	%rd195, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd126, %rd123, %rd17;
	.loc	1 28 43
	add.s64 	%rd127, %rd126, %rd195;
	.loc	1 28 86
	shl.b64 	%rd128, %rd126, 5;
	add.s64 	%rd129, %rd128, %rd201;
	.loc	1 31 35
	shl.b64 	%rd130, %rd127, 2;
	add.s64 	%rd131, %rd3, %rd130;
	shl.b64 	%rd132, %rd129, 2;
	add.s64 	%rd133, %rd2, %rd132;
	ld.global.f32 	%f34, [%rd133];
	ld.global.f32 	%f35, [%rd131];
	mul.f32 	%f36, %f35, %f34;
	.loc	1 28 127
	add.s64 	%rd134, %rd46, %rd195;
	.loc	1 34 35
	shl.b64 	%rd135, %rd134, 2;
	add.s64 	%rd136, %rd1, %rd135;
	ld.global.f32 	%f37, [%rd136];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f36, %f37, %f57;

$L__BB0_23:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	add.s64 	%rd138, %rd204, 8;
	// begin inline asm
	ld.global.nc.u64 %rd137, [%rd138];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	add.s64 	%rd139, %rd205, 8;
	// begin inline asm
	ld.global.nc.f64 %fd5, [%rd139];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd48, %fd5;
	.loc	1 25 40
	cvt.u32.u64 	%r18, %rd137;
	.loc	1 27 17
	setp.eq.s32 	%p22, %r18, -1;
	setp.eq.s64 	%p23, %rd48, 0;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB0_25;

	.loc	1 19 76
	shr.u64 	%rd198, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd140, %rd137, %rd17;
	.loc	1 28 43
	add.s64 	%rd141, %rd140, %rd198;
	.loc	1 28 86
	shl.b64 	%rd142, %rd140, 5;
	add.s64 	%rd143, %rd142, %rd201;
	.loc	1 31 35
	shl.b64 	%rd144, %rd141, 2;
	add.s64 	%rd145, %rd3, %rd144;
	shl.b64 	%rd146, %rd143, 2;
	add.s64 	%rd147, %rd2, %rd146;
	ld.global.f32 	%f38, [%rd147];
	ld.global.f32 	%f39, [%rd145];
	mul.f32 	%f40, %f39, %f38;
	.loc	1 28 127
	add.s64 	%rd148, %rd48, %rd198;
	.loc	1 34 35
	shl.b64 	%rd149, %rd148, 2;
	add.s64 	%rd150, %rd1, %rd149;
	ld.global.f32 	%f41, [%rd150];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f40, %f41, %f57;

$L__BB0_25:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	add.s64 	%rd152, %rd204, 16;
	// begin inline asm
	ld.global.nc.u64 %rd151, [%rd152];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	add.s64 	%rd153, %rd205, 16;
	// begin inline asm
	ld.global.nc.f64 %fd6, [%rd153];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd50, %fd6;
	.loc	1 25 40
	cvt.u32.u64 	%r19, %rd151;
	.loc	1 27 17
	setp.eq.s32 	%p25, %r19, -1;
	setp.eq.s64 	%p26, %rd50, 0;
	or.pred  	%p27, %p25, %p26;
	@%p27 bra 	$L__BB0_27;

	.loc	1 19 76
	shr.u64 	%rd197, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd154, %rd151, %rd17;
	.loc	1 28 43
	add.s64 	%rd155, %rd154, %rd197;
	.loc	1 28 86
	shl.b64 	%rd156, %rd154, 5;
	add.s64 	%rd157, %rd156, %rd201;
	.loc	1 31 35
	shl.b64 	%rd158, %rd155, 2;
	add.s64 	%rd159, %rd3, %rd158;
	shl.b64 	%rd160, %rd157, 2;
	add.s64 	%rd161, %rd2, %rd160;
	ld.global.f32 	%f42, [%rd161];
	ld.global.f32 	%f43, [%rd159];
	mul.f32 	%f44, %f43, %f42;
	.loc	1 28 127
	add.s64 	%rd162, %rd50, %rd197;
	.loc	1 34 35
	shl.b64 	%rd163, %rd162, 2;
	add.s64 	%rd164, %rd1, %rd163;
	ld.global.f32 	%f45, [%rd164];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f44, %f45, %f57;

$L__BB0_27:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 21 40
	add.s64 	%rd166, %rd204, 24;
	// begin inline asm
	ld.global.nc.u64 %rd165, [%rd166];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 22 37
	add.s64 	%rd167, %rd205, 24;
	// begin inline asm
	ld.global.nc.f64 %fd7, [%rd167];
	// end inline asm
	.loc	1 22 37
	cvt.rzi.s64.f64 	%rd52, %fd7;
	.loc	1 25 40
	cvt.u32.u64 	%r20, %rd165;
	.loc	1 27 17
	setp.eq.s32 	%p28, %r20, -1;
	setp.eq.s64 	%p29, %rd52, 0;
	or.pred  	%p30, %p28, %p29;
	@%p30 bra 	$L__BB0_29;

	.loc	1 19 76
	shr.u64 	%rd196, %rd201, 5;
	.loc	1 26 17
	sub.s64 	%rd168, %rd165, %rd17;
	.loc	1 28 43
	add.s64 	%rd169, %rd168, %rd196;
	.loc	1 28 86
	shl.b64 	%rd170, %rd168, 5;
	add.s64 	%rd171, %rd170, %rd201;
	.loc	1 31 35
	shl.b64 	%rd172, %rd169, 2;
	add.s64 	%rd173, %rd3, %rd172;
	shl.b64 	%rd174, %rd171, 2;
	add.s64 	%rd175, %rd2, %rd174;
	ld.global.f32 	%f46, [%rd175];
	ld.global.f32 	%f47, [%rd173];
	mul.f32 	%f48, %f47, %f46;
	.loc	1 28 127
	add.s64 	%rd176, %rd52, %rd196;
	.loc	1 34 35
	shl.b64 	%rd177, %rd176, 2;
	add.s64 	%rd178, %rd1, %rd177;
	ld.global.f32 	%f49, [%rd178];
	.loc	1 37 21
	fma.rn.f32 	%f57, %f48, %f49, %f57;

$L__BB0_29:
	.loc	1 20 44
	add.s64 	%rd202, %rd202, 4;
	.loc	1 20 13
	setp.lt.u64 	%p31, %rd202, %rd11;
	add.s64 	%rd204, %rd204, 32;
	add.s64 	%rd205, %rd205, 32;
	@%p31 bra 	$L__BB0_21;

$L__BB0_30:
	.loc	1 0 13
	shl.b64 	%rd186, %rd8, 5;
	.loc	1 19 76
	shr.u64 	%rd185, %rd201, 5;
	add.s64 	%rd179, %rd185, %rd8;
	.loc	1 44 27
	shl.b64 	%rd180, %rd179, 2;
	add.s64 	%rd181, %rd30, %rd180;
	ld.global.f32 	%f50, [%rd181];
	mul.f32 	%f51, %f57, %f50;
	.loc	1 19 35
	add.s64 	%rd182, %rd201, %rd186;
	.loc	1 44 55
	shl.b64 	%rd183, %rd182, 2;
	add.s64 	%rd184, %rd29, %rd183;
	st.global.f32 	[%rd184], %f51;
	.loc	1 17 29
	add.s64 	%rd201, %rd201, %rd16;
	.loc	1 17 9
	setp.lt.s64 	%p32, %rd201, %rd9;
	@%p32 bra 	$L__BB0_9;

$L__BB0_31:
	.loc	1 47 1
	ret;

}
	// .globl	K5
.visible .entry K5(
	.param .u64 K5_param_0,
	.param .u64 K5_param_1,
	.param .u64 K5_param_2,
	.param .u64 K5_param_3,
	.param .u64 K5_param_4,
	.param .u64 K5_param_5,
	.param .u64 K5_param_6,
	.param .u64 K5_param_7,
	.param .u64 K5_param_8,
	.param .u64 K5_param_9,
	.param .u64 K5_param_10,
	.param .u64 K5_param_11,
	.param .u64 K5_param_12
)
{
	.reg .pred 	%p<33>;
	.reg .f32 	%f<62>;
	.reg .b32 	%r<21>;
	.reg .f64 	%fd<8>;
	.reg .b64 	%rd<206>;
	.loc	1 48 0


	ld.param.u64 	%rd67, [K5_param_0];
	ld.param.u64 	%rd68, [K5_param_1];
	ld.param.u64 	%rd57, [K5_param_2];
	ld.param.u64 	%rd69, [K5_param_3];
	ld.param.u64 	%rd58, [K5_param_4];
	ld.param.u64 	%rd59, [K5_param_5];
	ld.param.u64 	%rd60, [K5_param_6];
	ld.param.u64 	%rd61, [K5_param_7];
	ld.param.u64 	%rd62, [K5_param_8];
	ld.param.u64 	%rd63, [K5_param_9];
	ld.param.u64 	%rd64, [K5_param_10];
	ld.param.u64 	%rd65, [K5_param_11];
	ld.param.u64 	%rd66, [K5_param_12];
	.loc	1 57 26
	cvta.to.global.u64 	%rd1, %rd69;
	cvta.to.global.u64 	%rd2, %rd68;
	cvta.to.global.u64 	%rd3, %rd67;
	mov.u32 	%r3, %tid.x;
	cvt.u64.u32 	%rd4, %r3;
	and.b64  	%rd70, %rd65, -4294967296;
	setp.eq.s64 	%p1, %rd70, 0;
	@%p1 bra 	$L__BB1_2;

	.loc	1 0 26
	div.s64 	%rd199, %rd4, %rd65;
	bra.uni 	$L__BB1_3;

$L__BB1_2:
	cvt.u32.u64 	%r4, %rd65;
	cvt.u32.u64 	%r5, %rd4;
	div.u32 	%r6, %r5, %r4;
	cvt.u64.u32 	%rd199, %r6;

$L__BB1_3:
	.loc	1 57 26
	mov.u32 	%r7, %ctaid.x;
	cvt.u64.u32 	%rd71, %r7;
	mul.lo.s64 	%rd72, %rd71, %rd66;
	add.s64 	%rd8, %rd199, %rd72;
	.loc	1 58 5
	setp.ge.s64 	%p2, %rd8, %rd62;
	@%p2 bra 	$L__BB1_31;

	.loc	1 59 32
	mul.lo.s64 	%rd9, %rd64, %rd63;
	.loc	1 60 27
	shl.b64 	%rd75, %rd8, 2;
	add.s64 	%rd73, %rd59, %rd75;
	.loc	1 60 29
	.loc	2 124 107, function_name $L__info_string0, inlined_at 1 60 29
	// begin inline asm
	ld.global.nc.u32 %r8, [%rd73];
	// end inline asm
	.loc	1 60 29
	cvt.u64.u32 	%rd10, %r8;
	.loc	1 61 27
	add.s64 	%rd74, %rd73, 4;
	.loc	1 61 29
	.loc	2 124 107, function_name $L__info_string0, inlined_at 1 61 29
	// begin inline asm
	ld.global.nc.u32 %r9, [%rd74];
	// end inline asm
	.loc	1 61 29
	cvt.u64.u32 	%rd11, %r9;
	@%p1 bra 	$L__BB1_6;

	.loc	1 0 29
	rem.s64 	%rd201, %rd4, %rd65;
	bra.uni 	$L__BB1_7;

$L__BB1_6:
	cvt.u32.u64 	%r10, %rd65;
	cvt.u32.u64 	%r11, %rd4;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd201, %r12;

$L__BB1_7:
	.loc	1 63 9
	setp.ge.s64 	%p4, %rd201, %rd9;
	@%p4 bra 	$L__BB1_31;

	.loc	1 0 9
	cvt.u32.u64 	%r1, %rd11;
	cvt.u32.u64 	%r2, %rd10;
	.loc	1 63 29
	mov.u32 	%r13, %ntid.x;
	cvt.u64.u32 	%rd16, %r13;
	shl.b64 	%rd17, %rd8, 32;
	.loc	1 66 13
	not.b64 	%rd77, %rd10;
	add.s64 	%rd18, %rd77, %rd11;
	sub.s64 	%rd78, %rd11, %rd10;
	and.b64  	%rd19, %rd78, 3;
	shl.b64 	%rd79, %rd10, 3;
	add.s64 	%rd21, %rd61, %rd79;
	add.s64 	%rd22, %rd21, 8;
	add.s64 	%rd23, %rd60, %rd79;
	add.s64 	%rd24, %rd23, 8;
	add.s64 	%rd26, %rd21, 16;
	add.s64 	%rd27, %rd23, 16;
	add.s64 	%rd28, %rd10, 3;
	.loc	1 57 26
	cvta.to.global.u64 	%rd29, %rd58;
	cvta.to.global.u64 	%rd30, %rd57;
	setp.ge.u32 	%p5, %r2, %r1;
	mov.f32 	%f18, 0f00000000;
	setp.eq.s64 	%p6, %rd19, 0;
	setp.lt.u64 	%p18, %rd18, 3;
	setp.eq.s64 	%p10, %rd19, 1;

$L__BB1_9:
	.loc	1 66 13
	mov.f32 	%f57, %f18;
	@%p5 bra 	$L__BB1_30;

	.loc	1 73 17
	mov.u64 	%rd202, %rd10;
	mov.f32 	%f57, %f18;
	@%p6 bra 	$L__BB1_19;

	.loc	1 0 17
	shl.b64 	%rd189, %rd10, 3;
	add.s64 	%rd188, %rd60, %rd189;
	add.s64 	%rd187, %rd61, %rd189;
	.loc	1 67 40
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	// begin inline asm
	ld.global.nc.u64 %rd80, [%rd187];
	// end inline asm
	.loc	1 68 37
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	// begin inline asm
	ld.global.nc.f64 %fd1, [%rd188];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd34, %fd1;
	.loc	1 71 40
	cvt.u32.u64 	%r14, %rd80;
	.loc	1 73 17
	setp.eq.s32 	%p7, %r14, -1;
	setp.eq.s64 	%p8, %rd34, 0;
	mov.f32 	%f57, 0f00000000;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB1_13;

	.loc	1 65 76
	shr.u64 	%rd194, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd83, %rd80, %rd17;
	.loc	1 74 43
	shl.b64 	%rd84, %rd83, 5;
	add.s64 	%rd85, %rd84, %rd201;
	.loc	1 77 35
	shl.b64 	%rd86, %rd85, 2;
	add.s64 	%rd87, %rd3, %rd86;
	.loc	1 74 84
	add.s64 	%rd88, %rd83, %rd194;
	.loc	1 77 35
	shl.b64 	%rd89, %rd88, 2;
	add.s64 	%rd90, %rd2, %rd89;
	ld.global.f32 	%f22, [%rd90];
	ld.global.f32 	%f23, [%rd87];
	mul.f32 	%f24, %f23, %f22;
	.loc	1 74 127
	add.s64 	%rd91, %rd34, %rd194;
	.loc	1 80 35
	shl.b64 	%rd92, %rd91, 2;
	add.s64 	%rd93, %rd1, %rd92;
	ld.global.f32 	%f25, [%rd93];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f24, %f25, 0f00000000;

$L__BB1_13:
	.loc	1 0 21
	add.s64 	%rd202, %rd10, 1;
	.loc	1 66 13
	@%p10 bra 	$L__BB1_19;

	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	// begin inline asm
	ld.global.nc.u64 %rd94, [%rd22];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	// begin inline asm
	ld.global.nc.f64 %fd2, [%rd24];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd36, %fd2;
	.loc	1 71 40
	cvt.u32.u64 	%r15, %rd94;
	.loc	1 73 17
	setp.eq.s32 	%p11, %r15, -1;
	setp.eq.s64 	%p12, %rd36, 0;
	or.pred  	%p13, %p11, %p12;
	@%p13 bra 	$L__BB1_16;

	.loc	1 65 76
	shr.u64 	%rd193, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd97, %rd94, %rd17;
	.loc	1 74 43
	shl.b64 	%rd98, %rd97, 5;
	add.s64 	%rd99, %rd98, %rd201;
	.loc	1 77 35
	shl.b64 	%rd100, %rd99, 2;
	add.s64 	%rd101, %rd3, %rd100;
	.loc	1 74 84
	add.s64 	%rd102, %rd97, %rd193;
	.loc	1 77 35
	shl.b64 	%rd103, %rd102, 2;
	add.s64 	%rd104, %rd2, %rd103;
	ld.global.f32 	%f26, [%rd104];
	ld.global.f32 	%f27, [%rd101];
	mul.f32 	%f28, %f27, %f26;
	.loc	1 74 127
	add.s64 	%rd105, %rd36, %rd193;
	.loc	1 80 35
	shl.b64 	%rd106, %rd105, 2;
	add.s64 	%rd107, %rd1, %rd106;
	ld.global.f32 	%f29, [%rd107];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f28, %f29, %f57;

$L__BB1_16:
	.loc	1 0 21
	add.s64 	%rd202, %rd10, 2;
	setp.eq.s64 	%p14, %rd19, 2;
	.loc	1 66 13
	@%p14 bra 	$L__BB1_19;

	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	// begin inline asm
	ld.global.nc.u64 %rd108, [%rd26];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	// begin inline asm
	ld.global.nc.f64 %fd3, [%rd27];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd38, %fd3;
	.loc	1 71 40
	cvt.u32.u64 	%r16, %rd108;
	.loc	1 73 17
	setp.eq.s32 	%p15, %r16, -1;
	setp.eq.s64 	%p16, %rd38, 0;
	or.pred  	%p17, %p15, %p16;
	mov.u64 	%rd202, %rd28;
	@%p17 bra 	$L__BB1_19;

	.loc	1 65 76
	shr.u64 	%rd192, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd111, %rd108, %rd17;
	.loc	1 74 43
	shl.b64 	%rd112, %rd111, 5;
	add.s64 	%rd113, %rd112, %rd201;
	.loc	1 77 35
	shl.b64 	%rd114, %rd113, 2;
	add.s64 	%rd115, %rd3, %rd114;
	.loc	1 74 84
	add.s64 	%rd116, %rd111, %rd192;
	.loc	1 77 35
	shl.b64 	%rd117, %rd116, 2;
	add.s64 	%rd118, %rd2, %rd117;
	ld.global.f32 	%f30, [%rd118];
	ld.global.f32 	%f31, [%rd115];
	mul.f32 	%f32, %f31, %f30;
	.loc	1 74 127
	add.s64 	%rd119, %rd38, %rd192;
	.loc	1 80 35
	shl.b64 	%rd120, %rd119, 2;
	add.s64 	%rd121, %rd1, %rd120;
	ld.global.f32 	%f33, [%rd121];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f32, %f33, %f57;
	mov.u64 	%rd202, %rd28;

$L__BB1_19:
	.loc	1 73 17
	@%p18 bra 	$L__BB1_30;

	shl.b64 	%rd122, %rd202, 3;
	add.s64 	%rd204, %rd61, %rd122;
	add.s64 	%rd205, %rd60, %rd122;

$L__BB1_21:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	// begin inline asm
	ld.global.nc.u64 %rd123, [%rd204];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	// begin inline asm
	ld.global.nc.f64 %fd4, [%rd205];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd46, %fd4;
	.loc	1 71 40
	cvt.u32.u64 	%r17, %rd123;
	.loc	1 73 17
	setp.eq.s32 	%p19, %r17, -1;
	setp.eq.s64 	%p20, %rd46, 0;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB1_23;

	.loc	1 65 76
	shr.u64 	%rd195, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd126, %rd123, %rd17;
	.loc	1 74 43
	shl.b64 	%rd127, %rd126, 5;
	add.s64 	%rd128, %rd127, %rd201;
	.loc	1 77 35
	shl.b64 	%rd129, %rd128, 2;
	add.s64 	%rd130, %rd3, %rd129;
	.loc	1 74 84
	add.s64 	%rd131, %rd126, %rd195;
	.loc	1 77 35
	shl.b64 	%rd132, %rd131, 2;
	add.s64 	%rd133, %rd2, %rd132;
	ld.global.f32 	%f34, [%rd133];
	ld.global.f32 	%f35, [%rd130];
	mul.f32 	%f36, %f35, %f34;
	.loc	1 74 127
	add.s64 	%rd134, %rd46, %rd195;
	.loc	1 80 35
	shl.b64 	%rd135, %rd134, 2;
	add.s64 	%rd136, %rd1, %rd135;
	ld.global.f32 	%f37, [%rd136];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f36, %f37, %f57;

$L__BB1_23:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	add.s64 	%rd138, %rd204, 8;
	// begin inline asm
	ld.global.nc.u64 %rd137, [%rd138];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	add.s64 	%rd139, %rd205, 8;
	// begin inline asm
	ld.global.nc.f64 %fd5, [%rd139];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd48, %fd5;
	.loc	1 71 40
	cvt.u32.u64 	%r18, %rd137;
	.loc	1 73 17
	setp.eq.s32 	%p22, %r18, -1;
	setp.eq.s64 	%p23, %rd48, 0;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB1_25;

	.loc	1 65 76
	shr.u64 	%rd198, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd140, %rd137, %rd17;
	.loc	1 74 43
	shl.b64 	%rd141, %rd140, 5;
	add.s64 	%rd142, %rd141, %rd201;
	.loc	1 77 35
	shl.b64 	%rd143, %rd142, 2;
	add.s64 	%rd144, %rd3, %rd143;
	.loc	1 74 84
	add.s64 	%rd145, %rd140, %rd198;
	.loc	1 77 35
	shl.b64 	%rd146, %rd145, 2;
	add.s64 	%rd147, %rd2, %rd146;
	ld.global.f32 	%f38, [%rd147];
	ld.global.f32 	%f39, [%rd144];
	mul.f32 	%f40, %f39, %f38;
	.loc	1 74 127
	add.s64 	%rd148, %rd48, %rd198;
	.loc	1 80 35
	shl.b64 	%rd149, %rd148, 2;
	add.s64 	%rd150, %rd1, %rd149;
	ld.global.f32 	%f41, [%rd150];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f40, %f41, %f57;

$L__BB1_25:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	add.s64 	%rd152, %rd204, 16;
	// begin inline asm
	ld.global.nc.u64 %rd151, [%rd152];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	add.s64 	%rd153, %rd205, 16;
	// begin inline asm
	ld.global.nc.f64 %fd6, [%rd153];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd50, %fd6;
	.loc	1 71 40
	cvt.u32.u64 	%r19, %rd151;
	.loc	1 73 17
	setp.eq.s32 	%p25, %r19, -1;
	setp.eq.s64 	%p26, %rd50, 0;
	or.pred  	%p27, %p25, %p26;
	@%p27 bra 	$L__BB1_27;

	.loc	1 65 76
	shr.u64 	%rd197, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd154, %rd151, %rd17;
	.loc	1 74 43
	shl.b64 	%rd155, %rd154, 5;
	add.s64 	%rd156, %rd155, %rd201;
	.loc	1 77 35
	shl.b64 	%rd157, %rd156, 2;
	add.s64 	%rd158, %rd3, %rd157;
	.loc	1 74 84
	add.s64 	%rd159, %rd154, %rd197;
	.loc	1 77 35
	shl.b64 	%rd160, %rd159, 2;
	add.s64 	%rd161, %rd2, %rd160;
	ld.global.f32 	%f42, [%rd161];
	ld.global.f32 	%f43, [%rd158];
	mul.f32 	%f44, %f43, %f42;
	.loc	1 74 127
	add.s64 	%rd162, %rd50, %rd197;
	.loc	1 80 35
	shl.b64 	%rd163, %rd162, 2;
	add.s64 	%rd164, %rd1, %rd163;
	ld.global.f32 	%f45, [%rd164];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f44, %f45, %f57;

$L__BB1_27:
	.loc	2 125 125, function_name $L__info_string1, inlined_at 1 67 40
	add.s64 	%rd166, %rd204, 24;
	// begin inline asm
	ld.global.nc.u64 %rd165, [%rd166];
	// end inline asm
	.loc	2 135 89, function_name $L__info_string2, inlined_at 1 68 37
	add.s64 	%rd167, %rd205, 24;
	// begin inline asm
	ld.global.nc.f64 %fd7, [%rd167];
	// end inline asm
	.loc	1 68 37
	cvt.rzi.s64.f64 	%rd52, %fd7;
	.loc	1 71 40
	cvt.u32.u64 	%r20, %rd165;
	.loc	1 73 17
	setp.eq.s32 	%p28, %r20, -1;
	setp.eq.s64 	%p29, %rd52, 0;
	or.pred  	%p30, %p28, %p29;
	@%p30 bra 	$L__BB1_29;

	.loc	1 65 76
	shr.u64 	%rd196, %rd201, 5;
	.loc	1 72 17
	sub.s64 	%rd168, %rd165, %rd17;
	.loc	1 74 43
	shl.b64 	%rd169, %rd168, 5;
	add.s64 	%rd170, %rd169, %rd201;
	.loc	1 77 35
	shl.b64 	%rd171, %rd170, 2;
	add.s64 	%rd172, %rd3, %rd171;
	.loc	1 74 84
	add.s64 	%rd173, %rd168, %rd196;
	.loc	1 77 35
	shl.b64 	%rd174, %rd173, 2;
	add.s64 	%rd175, %rd2, %rd174;
	ld.global.f32 	%f46, [%rd175];
	ld.global.f32 	%f47, [%rd172];
	mul.f32 	%f48, %f47, %f46;
	.loc	1 74 127
	add.s64 	%rd176, %rd52, %rd196;
	.loc	1 80 35
	shl.b64 	%rd177, %rd176, 2;
	add.s64 	%rd178, %rd1, %rd177;
	ld.global.f32 	%f49, [%rd178];
	.loc	1 83 21
	fma.rn.f32 	%f57, %f48, %f49, %f57;

$L__BB1_29:
	.loc	1 66 44
	add.s64 	%rd202, %rd202, 4;
	.loc	1 66 13
	setp.lt.u64 	%p31, %rd202, %rd11;
	add.s64 	%rd204, %rd204, 32;
	add.s64 	%rd205, %rd205, 32;
	@%p31 bra 	$L__BB1_21;

$L__BB1_30:
	.loc	1 0 13
	shl.b64 	%rd186, %rd8, 5;
	.loc	1 65 76
	shr.u64 	%rd185, %rd201, 5;
	add.s64 	%rd179, %rd185, %rd8;
	.loc	1 90 27
	shl.b64 	%rd180, %rd179, 2;
	add.s64 	%rd181, %rd30, %rd180;
	ld.global.f32 	%f50, [%rd181];
	mul.f32 	%f51, %f57, %f50;
	.loc	1 65 35
	add.s64 	%rd182, %rd201, %rd186;
	.loc	1 90 55
	shl.b64 	%rd183, %rd182, 2;
	add.s64 	%rd184, %rd29, %rd183;
	st.global.f32 	[%rd184], %f51;
	.loc	1 63 29
	add.s64 	%rd201, %rd201, %rd16;
	.loc	1 63 9
	setp.lt.s64 	%p32, %rd201, %rd9;
	@%p32 bra 	$L__BB1_9;

$L__BB1_31:
	.loc	1 93 1
	ret;

}
	.file	1 "/mnt/c/Nithin stuff/Final Year Project/Organisation Repos/Seastar/benchmarking/tgcn/dynamic/./egl_kernel.cu"
	.file	2 "/usr/local/cuda-11.7/bin/../targets/x86_64-linux/include/sm_32_intrinsics.hpp"
	.section	.debug_str
	{
$L__info_string0:
.b8 95,90,78,51,56,95,73,78,84,69,82,78,65,76,95,102,99,102,97,55,100,48,101,95,49,51,95,101,103,108,95,107,101,114,110,101,108,95,99,117
.b8 95,75,52,53,95,95,108,100,103,69,80,75,106,0
$L__info_string1:
.b8 95,90,78,51,56,95,73,78,84,69,82,78,65,76,95,102,99,102,97,55,100,48,101,95,49,51,95,101,103,108,95,107,101,114,110,101,108,95,99,117
.b8 95,75,52,53,95,95,108,100,103,69,80,75,121,0
$L__info_string2:
.b8 95,90,78,51,56,95,73,78,84,69,82,78,65,76,95,102,99,102,97,55,100,48,101,95,49,51,95,101,103,108,95,107,101,114,110,101,108,95,99,117
.b8 95,75,52,53,95,95,108,100,103,69,80,75,100,0

	}
