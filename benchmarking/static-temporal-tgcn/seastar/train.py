import argparse
import time
import numpy as np
import pandas as pd
import torch
import snoop
import pynvml
import sys
import os

from model import STGraphTGCN
from stgraph.graph.static.StaticGraph import StaticGraph

from stgraph.dataset.WindmillOutputDataLoader import WindmillOutputDataLoader
from stgraph.dataset.WikiMathDataLoader import WikiMathDataLoader
from stgraph.dataset.HungaryCPDataLoader import HungaryCPDataLoader
from stgraph.dataset.PedalMeDataLoader import PedalMeDataLoader
from stgraph.dataset.METRLADataLoader import METRLADataLoader
from stgraph.dataset.MontevideoBusDataLoader import MontevideoBusDataLoader

from stgraph.benchmark_tools.table import BenchmarkTable
from utils import to_default_device, get_default_device

from rich import inspect

def main(args):

    if torch.cuda.is_available():
        print("ðŸŽ‰ CUDA is available")
    else:
        print("ðŸ˜” CUDA is not available")
        quit()

    # Dummy object to account for CUDA context object
    Graph = StaticGraph([(0,0)], [1], 1)
    
    if args.dataset == "wiki":
        dataloader = WikiMathDataLoader('static-temporal', 'wikivital_mathematics', args.feat_size, args.cutoff_time, verbose=True, for_stgraph=True)
    elif args.dataset == "windmill":
        dataloader = WindmillOutputDataLoader('static-temporal', 'windmill_output', args.feat_size, args.cutoff_time, verbose=True, for_stgraph=True)
    elif args.dataset == "hungarycp":
        dataloader = HungaryCPDataLoader('static-temporal', 'HungaryCP', args.feat_size, args.cutoff_time, verbose=True, for_stgraph=True)
    elif args.dataset == "pedalme":
        dataloader = PedalMeDataLoader('static-temporal', 'pedalme', args.feat_size, args.cutoff_time, verbose=True, for_stgraph=True)
    elif args.dataset == "metrla":
        dataloader = METRLADataLoader('static-temporal', 'METRLA', args.feat_size, args.feat_size, args.cutoff_time, verbose=True, for_stgraph=True)
    elif args.dataset == "monte":
        dataloader = MontevideoBusDataLoader('static-temporal', 'montevideobus', args.feat_size, args.cutoff_time, verbose=True, for_stgraph=True)
    else:
        print("ðŸ˜” Unrecognized dataset")
        quit()

    edge_list = dataloader.get_edges()
    edge_weight_list = dataloader.get_edge_weights()
    targets = dataloader.get_all_targets()
    
    pynvml.nvmlInit()
    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
    initial_used_gpu_mem = pynvml.nvmlDeviceGetMemoryInfo(handle).used
    G = StaticGraph(edge_list, edge_weight_list, dataloader.num_nodes)
    graph_mem = pynvml.nvmlDeviceGetMemoryInfo(handle).used - initial_used_gpu_mem

    edge_weight = to_default_device(torch.unsqueeze(torch.FloatTensor(edge_weight_list), 1))
    targets = to_default_device(torch.FloatTensor(np.array(targets)))

    num_hidden_units = args.num_hidden
    num_outputs = 1
    model = to_default_device(STGraphTGCN(args.feat_size, num_hidden_units, num_outputs))
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    # Logging Output
    total_timestamps = dataloader.total_timestamps
    print("Dataset: ", args.dataset)
    print("Num Nodes: ", dataloader.num_nodes)
    print("Num Edges: ", len(edge_list))
    print("Num Timestamps: ", dataloader.total_timestamps)

    backprop_every = args.backprop_every
    if backprop_every == 0:
        backprop_every = total_timestamps
    
    if total_timestamps % backprop_every == 0:
        num_iter = int(total_timestamps/backprop_every)
    else:
        num_iter = int(total_timestamps/backprop_every) + 1

    # metrics
    dur = []
    max_gpu = []
    table = BenchmarkTable(f"(STGraph Static-Temporal) TGCN on {dataloader.name} dataset", ["Epoch", "Time(s)", "MSE", "Used GPU Memory (Max MB)"])
    
    # normalization
    degs = torch.from_numpy(G.in_degrees()).type(torch.int32)
    norm = torch.pow(degs, -0.5)
    norm[torch.isinf(norm)] = 0
    norm = to_default_device(norm)
    G.set_ndata('norm', norm.unsqueeze(1))

    # train
    print("Training...\n")
    try:
        for epoch in range(args.num_epochs):
            torch.cuda.synchronize()
            torch.cuda.reset_peak_memory_stats(0)
            model.train()
            
            t0 = time.time()
            gpu_mem_arr = []
            cost_arr = []

            for index in range(num_iter):
                optimizer.zero_grad()
                cost = 0
                hidden_state = None
                y_hat = torch.randn((dataloader.num_nodes, args.feat_size), device=get_default_device())
                for k in range(backprop_every):
                    t = index * backprop_every + k

                    if t >= total_timestamps:
                        break

                    y_out, y_hat, hidden_state = model(G, y_hat, edge_weight, hidden_state)
                    cost = cost + torch.mean((y_out-targets[t])**2)
                
                if cost == 0:
                    break
        
                cost = cost / (backprop_every+1)
                cost.backward()
                optimizer.step()
                torch.cuda.synchronize()
                cost_arr.append(cost.item())

            used_gpu_mem = torch.cuda.max_memory_allocated(0) + graph_mem
            gpu_mem_arr.append(used_gpu_mem)

            run_time_this_epoch = time.time() - t0

            if epoch >= 3:
                dur.append(run_time_this_epoch)
                max_gpu.append(max(gpu_mem_arr))

            table.add_row([epoch, "{:.5f}".format(run_time_this_epoch), "{:.4f}".format(sum(cost_arr)/len(cost_arr)), "{:.4f}".format((max(gpu_mem_arr) * 1.0 / (1024**2)))])

        table.display()
        print('Average Time taken: {:6f}'.format(np.mean(dur)))
        return np.mean(dur), (max(max_gpu) * 1.0 / (1024**2))
    
    except RuntimeError as e:
        if 'out of memory' in str(e):
            table.add_row(["OOM", "OOM", "OOM", "OOM"])
            table.display()
        else:
            print("ðŸ˜” Something went wrong")
        return "OOM", "OOM"

def write_results(args, time_taken, max_gpu):
    cutoff = "whole"
    if args.cutoff_time < sys.maxsize:
        cutoff = str(args.cutoff_time)
    file_name = f"stgraph_{args.dataset}_T{cutoff}_B{args.backprop_every}_H{args.num_hidden}_F{args.feat_size}"
    df_data = pd.DataFrame([{'Filename': file_name, 'Time Taken (s)': time_taken, 'Max GPU Usage (MB)': max_gpu}])
    
    if os.path.exists('../../results/static-temporal.csv'):
        df = pd.read_csv('../../results/static-temporal.csv')
        df = pd.concat([df, df_data])
    else:
        df = df_data
    
    df.to_csv('../../results/static-temporal.csv', sep=',', index=False, encoding='utf-8')


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='STGraph Static TGCN')
    snoop.install(enabled=False)

    parser.add_argument("--dataset", type=str, default="wiki",
            help="Name of the Dataset (wiki, windmill, hungary_cp, pedalme, metrla, monte)")
    parser.add_argument("--backprop-every", type=int, default=0,
            help="Feature size of nodes")
    parser.add_argument("--feat-size", type=int, default=8,
            help="Feature size of nodes")
    parser.add_argument("--num-hidden", type=int, default=100,
            help="Number of hidden units")
    parser.add_argument("--lr", type=float, default=1e-2,
            help="learning rate")
    parser.add_argument("--cutoff-time", type=int, default=sys.maxsize,
            help="learning rate")
    parser.add_argument("--num-epochs", type=int, default=1,
            help="number of training epochs")
    args = parser.parse_args()
    
    print(args)
    time_taken, max_gpu = main(args)
    write_results(args, time_taken, max_gpu)