//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_61
.address_size 64

	// .globl	K4
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9all_hostsE = 1;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_35_bitE = 2;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_37_bitE = 4;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_50_bitE = 8;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_52_bitE = 16;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_53_bitE = 32;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_60_bitE = 64;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_61_bitE = 128;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_62_bitE = 256;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_70_bitE = 512;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_72_bitE = 1024;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_75_bitE = 2048;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_80_bitE = 4096;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_86_bitE = 8192;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_87_bitE = 16384;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_89_bitE = 32768;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail9sm_90_bitE = 65536;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target6detail11all_devicesE = 131070;
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target7is_hostE[8] = {1, 0, 0, 0, 0, 0, 0, 0};
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target9is_deviceE[8] = {254, 255, 1, 0, 0, 0, 0, 0};
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target10any_targetE[8] = {255, 255, 1, 0, 0, 0, 0, 0};
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target9no_targetE[8];
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_35E = 35;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_37E = 37;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_50E = 50;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_52E = 52;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_53E = 53;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_60E = 60;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_61E = 61;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_62E = 62;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_70E = 70;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_72E = 72;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_75E = 75;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_80E = 80;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_86E = 86;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_87E = 87;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_89E = 89;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K42nv6target5sm_90E = 90;

.visible .entry K4(
	.param .u64 K4_param_0,
	.param .u64 K4_param_1,
	.param .u64 K4_param_2,
	.param .u64 K4_param_3,
	.param .u64 K4_param_4,
	.param .u64 K4_param_5,
	.param .u64 K4_param_6,
	.param .u32 K4_param_7,
	.param .u32 K4_param_8,
	.param .u32 K4_param_9,
	.param .u32 K4_param_10,
	.param .u32 K4_param_11
)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<141>;
	.reg .b32 	%r<81>;
	.reg .f64 	%fd<22>;
	.reg .b64 	%rd<80>;


	ld.param.u64 	%rd26, [K4_param_0];
	ld.param.u64 	%rd21, [K4_param_1];
	ld.param.u64 	%rd27, [K4_param_2];
	ld.param.u64 	%rd22, [K4_param_3];
	ld.param.u64 	%rd23, [K4_param_4];
	ld.param.u64 	%rd24, [K4_param_5];
	ld.param.u64 	%rd25, [K4_param_6];
	ld.param.u32 	%r22, [K4_param_7];
	ld.param.u32 	%r19, [K4_param_8];
	ld.param.u32 	%r20, [K4_param_9];
	ld.param.u32 	%r21, [K4_param_10];
	ld.param.u32 	%r23, [K4_param_11];
	cvta.to.global.u64 	%rd1, %rd27;
	cvta.to.global.u64 	%rd2, %rd26;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	div.u32 	%r25, %r1, %r21;
	mad.lo.s32 	%r2, %r24, %r23, %r25;
	setp.ge.s32 	%p1, %r2, %r22;
	@%p1 bra 	$L__BB0_13;

	mul.lo.s32 	%r3, %r20, %r19;
	mul.wide.s32 	%rd30, %r2, 4;
	add.s64 	%rd28, %rd23, %rd30;
	// begin inline asm
	ld.global.nc.s32 %r26, [%rd28];
	// end inline asm
	add.s64 	%rd29, %rd28, 4;
	// begin inline asm
	ld.global.nc.s32 %r27, [%rd29];
	// end inline asm
	rem.u32 	%r78, %r1, %r21;
	setp.ge.s32 	%p2, %r78, %r3;
	@%p2 bra 	$L__BB0_13;

	sub.s32 	%r29, %r27, %r26;
	and.b32  	%r9, %r29, 3;
	mul.wide.s32 	%rd31, %r26, 4;
	add.s64 	%rd3, %rd25, %rd31;
	add.s64 	%rd4, %rd24, %rd31;
	add.s64 	%rd5, %rd3, 4;
	add.s64 	%rd6, %rd4, 4;
	add.s64 	%rd7, %rd3, 8;
	add.s64 	%rd8, %rd4, 8;
	add.s64 	%rd9, %rd24, 12;
	add.s64 	%rd10, %rd24, 8;
	add.s64 	%rd11, %rd24, 4;
	add.s64 	%rd12, %rd25, 12;
	add.s64 	%rd13, %rd25, 8;
	add.s64 	%rd14, %rd25, 4;
	cvta.to.global.u64 	%rd15, %rd21;
	cvta.to.global.u64 	%rd16, %rd22;

$L__BB0_3:
	add.s32 	%r14, %r78, %r2;
	setp.gt.s32 	%p3, %r27, %r26;
	@%p3 bra 	$L__BB0_5;
	bra.uni 	$L__BB0_4;

$L__BB0_5:
	setp.eq.s32 	%p4, %r9, 0;
	mul.wide.s32 	%rd32, %r14, 4;
	add.s64 	%rd17, %rd15, %rd32;
	mov.f32 	%f140, 0f00000000;
	mov.u32 	%r79, %r26;
	@%p4 bra 	$L__BB0_9;

	add.s32 	%r79, %r26, 1;
	setp.eq.s32 	%p5, %r9, 1;
	// begin inline asm
	ld.global.nc.s32 %r30, [%rd3];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r31, [%rd4];
	// end inline asm
	add.s32 	%r32, %r30, %r78;
	add.s32 	%r33, %r31, %r78;
	mul.wide.s32 	%rd35, %r32, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.f32 	%f12, [%rd17];
	ld.global.f32 	%f13, [%rd36];
	add.rn.f32 	%f14, %f13, %f12;
	setp.gt.f32 	%p6, %f14, 0f00000000;
	cvt.f64.f32 	%fd1, %f14;
	mul.rn.f64 	%fd2, %fd1, 0d3FC999999999999A;
	selp.f64 	%fd3, %fd1, %fd2, %p6;
	cvt.rn.f32.f64 	%f15, %fd3;
	mov.f32 	%f16, 0f3F000000;
	mov.f32 	%f17, 0f3BBB989D;
	fma.rn.f32 	%f18, %f15, %f17, %f16;
	mov.f32 	%f19, 0f3FB8AA3B;
	mov.f32 	%f20, 0f437C0000;
	cvt.sat.f32.f32 	%f21, %f18;
	mov.f32 	%f22, 0f4B400001;
	fma.rm.f32 	%f23, %f21, %f20, %f22;
	add.rn.f32 	%f24, %f23, 0fCB40007F;
	neg.f32 	%f25, %f24;
	fma.rn.f32 	%f26, %f15, %f19, %f25;
	mov.f32 	%f27, 0f32A57060;
	fma.rn.f32 	%f28, %f15, %f27, %f26;
	mov.b32 	%r34, %f23;
	shl.b32 	%r35, %r34, 23;
	mov.b32 	%f29, %r35;
	ex2.approx.ftz.f32 	%f30, %f28;
	mul.rn.f32 	%f31, %f30, %f29;
	mul.wide.s32 	%rd37, %r33, 4;
	add.s64 	%rd38, %rd1, %rd37;
	st.global.f32 	[%rd38], %f31;
	add.rn.f32 	%f140, %f31, 0f00000000;
	@%p5 bra 	$L__BB0_9;

	add.s32 	%r79, %r26, 2;
	setp.eq.s32 	%p7, %r9, 2;
	// begin inline asm
	ld.global.nc.s32 %r36, [%rd5];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r37, [%rd6];
	// end inline asm
	add.s32 	%r38, %r36, %r78;
	add.s32 	%r39, %r37, %r78;
	mul.wide.s32 	%rd41, %r38, 4;
	add.s64 	%rd42, %rd2, %rd41;
	ld.global.f32 	%f32, [%rd17];
	ld.global.f32 	%f33, [%rd42];
	add.rn.f32 	%f34, %f33, %f32;
	setp.gt.f32 	%p8, %f34, 0f00000000;
	cvt.f64.f32 	%fd4, %f34;
	mul.rn.f64 	%fd5, %fd4, 0d3FC999999999999A;
	selp.f64 	%fd6, %fd4, %fd5, %p8;
	cvt.rn.f32.f64 	%f35, %fd6;
	fma.rn.f32 	%f38, %f35, %f17, %f16;
	cvt.sat.f32.f32 	%f41, %f38;
	fma.rm.f32 	%f43, %f41, %f20, %f22;
	add.rn.f32 	%f44, %f43, 0fCB40007F;
	neg.f32 	%f45, %f44;
	fma.rn.f32 	%f46, %f35, %f19, %f45;
	fma.rn.f32 	%f48, %f35, %f27, %f46;
	mov.b32 	%r40, %f43;
	shl.b32 	%r41, %r40, 23;
	mov.b32 	%f49, %r41;
	ex2.approx.ftz.f32 	%f50, %f48;
	mul.rn.f32 	%f51, %f50, %f49;
	mul.wide.s32 	%rd43, %r39, 4;
	add.s64 	%rd44, %rd1, %rd43;
	st.global.f32 	[%rd44], %f51;
	add.rn.f32 	%f140, %f140, %f51;
	@%p7 bra 	$L__BB0_9;

	add.s32 	%r79, %r26, 3;
	// begin inline asm
	ld.global.nc.s32 %r42, [%rd7];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r43, [%rd8];
	// end inline asm
	add.s32 	%r44, %r42, %r78;
	add.s32 	%r45, %r43, %r78;
	mul.wide.s32 	%rd47, %r44, 4;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.f32 	%f52, [%rd17];
	ld.global.f32 	%f53, [%rd48];
	add.rn.f32 	%f54, %f53, %f52;
	setp.gt.f32 	%p9, %f54, 0f00000000;
	cvt.f64.f32 	%fd7, %f54;
	mul.rn.f64 	%fd8, %fd7, 0d3FC999999999999A;
	selp.f64 	%fd9, %fd7, %fd8, %p9;
	cvt.rn.f32.f64 	%f55, %fd9;
	mov.f32 	%f56, 0f3F000000;
	mov.f32 	%f57, 0f3BBB989D;
	fma.rn.f32 	%f58, %f55, %f57, %f56;
	mov.f32 	%f59, 0f3FB8AA3B;
	mov.f32 	%f60, 0f437C0000;
	cvt.sat.f32.f32 	%f61, %f58;
	mov.f32 	%f62, 0f4B400001;
	fma.rm.f32 	%f63, %f61, %f60, %f62;
	add.rn.f32 	%f64, %f63, 0fCB40007F;
	neg.f32 	%f65, %f64;
	fma.rn.f32 	%f66, %f55, %f59, %f65;
	mov.f32 	%f67, 0f32A57060;
	fma.rn.f32 	%f68, %f55, %f67, %f66;
	mov.b32 	%r46, %f63;
	shl.b32 	%r47, %r46, 23;
	mov.b32 	%f69, %r47;
	ex2.approx.ftz.f32 	%f70, %f68;
	mul.rn.f32 	%f71, %f70, %f69;
	mul.wide.s32 	%rd49, %r45, 4;
	add.s64 	%rd50, %rd1, %rd49;
	st.global.f32 	[%rd50], %f71;
	add.rn.f32 	%f140, %f140, %f71;

$L__BB0_9:
	not.b32 	%r75, %r26;
	add.s32 	%r74, %r27, %r75;
	setp.lt.u32 	%p10, %r74, 3;
	@%p10 bra 	$L__BB0_12;

	mul.wide.s32 	%rd79, %r79, 4;

$L__BB0_11:
	ld.param.u64 	%rd78, [K4_param_5];
	ld.param.u64 	%rd77, [K4_param_6];
	add.s64 	%rd51, %rd77, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r48, [%rd51];
	// end inline asm
	add.s64 	%rd52, %rd78, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r49, [%rd52];
	// end inline asm
	add.s32 	%r56, %r48, %r78;
	add.s32 	%r57, %r49, %r78;
	mul.wide.s32 	%rd59, %r56, 4;
	add.s64 	%rd60, %rd2, %rd59;
	ld.global.f32 	%f72, [%rd17];
	ld.global.f32 	%f73, [%rd60];
	add.rn.f32 	%f74, %f73, %f72;
	setp.gt.f32 	%p11, %f74, 0f00000000;
	cvt.f64.f32 	%fd10, %f74;
	mul.rn.f64 	%fd11, %fd10, 0d3FC999999999999A;
	selp.f64 	%fd12, %fd10, %fd11, %p11;
	cvt.rn.f32.f64 	%f75, %fd12;
	mov.f32 	%f76, 0f3F000000;
	mov.f32 	%f77, 0f3BBB989D;
	fma.rn.f32 	%f78, %f75, %f77, %f76;
	mov.f32 	%f79, 0f3FB8AA3B;
	mov.f32 	%f80, 0f437C0000;
	cvt.sat.f32.f32 	%f81, %f78;
	mov.f32 	%f82, 0f4B400001;
	fma.rm.f32 	%f83, %f81, %f80, %f82;
	add.rn.f32 	%f84, %f83, 0fCB40007F;
	neg.f32 	%f85, %f84;
	fma.rn.f32 	%f86, %f75, %f79, %f85;
	mov.f32 	%f87, 0f32A57060;
	fma.rn.f32 	%f88, %f75, %f87, %f86;
	mov.b32 	%r58, %f83;
	shl.b32 	%r59, %r58, 23;
	mov.b32 	%f89, %r59;
	ex2.approx.ftz.f32 	%f90, %f88;
	mul.rn.f32 	%f91, %f90, %f89;
	mul.wide.s32 	%rd61, %r57, 4;
	add.s64 	%rd62, %rd1, %rd61;
	st.global.f32 	[%rd62], %f91;
	add.rn.f32 	%f92, %f140, %f91;
	add.s64 	%rd53, %rd14, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r50, [%rd53];
	// end inline asm
	add.s64 	%rd54, %rd11, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r51, [%rd54];
	// end inline asm
	add.s32 	%r60, %r50, %r78;
	add.s32 	%r61, %r51, %r78;
	mul.wide.s32 	%rd63, %r60, 4;
	add.s64 	%rd64, %rd2, %rd63;
	ld.global.f32 	%f93, [%rd17];
	ld.global.f32 	%f94, [%rd64];
	add.rn.f32 	%f95, %f94, %f93;
	setp.gt.f32 	%p12, %f95, 0f00000000;
	cvt.f64.f32 	%fd13, %f95;
	mul.rn.f64 	%fd14, %fd13, 0d3FC999999999999A;
	selp.f64 	%fd15, %fd13, %fd14, %p12;
	cvt.rn.f32.f64 	%f96, %fd15;
	fma.rn.f32 	%f97, %f96, %f77, %f76;
	cvt.sat.f32.f32 	%f98, %f97;
	fma.rm.f32 	%f99, %f98, %f80, %f82;
	add.rn.f32 	%f100, %f99, 0fCB40007F;
	neg.f32 	%f101, %f100;
	fma.rn.f32 	%f102, %f96, %f79, %f101;
	fma.rn.f32 	%f103, %f96, %f87, %f102;
	mov.b32 	%r62, %f99;
	shl.b32 	%r63, %r62, 23;
	mov.b32 	%f104, %r63;
	ex2.approx.ftz.f32 	%f105, %f103;
	mul.rn.f32 	%f106, %f105, %f104;
	mul.wide.s32 	%rd65, %r61, 4;
	add.s64 	%rd66, %rd1, %rd65;
	st.global.f32 	[%rd66], %f106;
	add.rn.f32 	%f107, %f92, %f106;
	add.s64 	%rd55, %rd13, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r52, [%rd55];
	// end inline asm
	add.s64 	%rd56, %rd10, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r53, [%rd56];
	// end inline asm
	add.s32 	%r64, %r52, %r78;
	add.s32 	%r65, %r53, %r78;
	mul.wide.s32 	%rd67, %r64, 4;
	add.s64 	%rd68, %rd2, %rd67;
	ld.global.f32 	%f108, [%rd17];
	ld.global.f32 	%f109, [%rd68];
	add.rn.f32 	%f110, %f109, %f108;
	setp.gt.f32 	%p13, %f110, 0f00000000;
	cvt.f64.f32 	%fd16, %f110;
	mul.rn.f64 	%fd17, %fd16, 0d3FC999999999999A;
	selp.f64 	%fd18, %fd16, %fd17, %p13;
	cvt.rn.f32.f64 	%f111, %fd18;
	fma.rn.f32 	%f112, %f111, %f77, %f76;
	cvt.sat.f32.f32 	%f113, %f112;
	fma.rm.f32 	%f114, %f113, %f80, %f82;
	add.rn.f32 	%f115, %f114, 0fCB40007F;
	neg.f32 	%f116, %f115;
	fma.rn.f32 	%f117, %f111, %f79, %f116;
	fma.rn.f32 	%f118, %f111, %f87, %f117;
	mov.b32 	%r66, %f114;
	shl.b32 	%r67, %r66, 23;
	mov.b32 	%f119, %r67;
	ex2.approx.ftz.f32 	%f120, %f118;
	mul.rn.f32 	%f121, %f120, %f119;
	mul.wide.s32 	%rd69, %r65, 4;
	add.s64 	%rd70, %rd1, %rd69;
	st.global.f32 	[%rd70], %f121;
	add.rn.f32 	%f122, %f107, %f121;
	add.s64 	%rd57, %rd12, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r54, [%rd57];
	// end inline asm
	add.s64 	%rd58, %rd9, %rd79;
	// begin inline asm
	ld.global.nc.s32 %r55, [%rd58];
	// end inline asm
	add.s32 	%r68, %r54, %r78;
	add.s32 	%r69, %r55, %r78;
	mul.wide.s32 	%rd71, %r68, 4;
	add.s64 	%rd72, %rd2, %rd71;
	ld.global.f32 	%f123, [%rd17];
	ld.global.f32 	%f124, [%rd72];
	add.rn.f32 	%f125, %f124, %f123;
	setp.gt.f32 	%p14, %f125, 0f00000000;
	cvt.f64.f32 	%fd19, %f125;
	mul.rn.f64 	%fd20, %fd19, 0d3FC999999999999A;
	selp.f64 	%fd21, %fd19, %fd20, %p14;
	cvt.rn.f32.f64 	%f126, %fd21;
	fma.rn.f32 	%f127, %f126, %f77, %f76;
	cvt.sat.f32.f32 	%f128, %f127;
	fma.rm.f32 	%f129, %f128, %f80, %f82;
	add.rn.f32 	%f130, %f129, 0fCB40007F;
	neg.f32 	%f131, %f130;
	fma.rn.f32 	%f132, %f126, %f79, %f131;
	fma.rn.f32 	%f133, %f126, %f87, %f132;
	mov.b32 	%r70, %f129;
	shl.b32 	%r71, %r70, 23;
	mov.b32 	%f134, %r71;
	ex2.approx.ftz.f32 	%f135, %f133;
	mul.rn.f32 	%f136, %f135, %f134;
	mul.wide.s32 	%rd73, %r69, 4;
	add.s64 	%rd74, %rd1, %rd73;
	st.global.f32 	[%rd74], %f136;
	add.rn.f32 	%f140, %f122, %f136;
	add.s64 	%rd79, %rd79, 16;
	add.s32 	%r79, %r79, 4;
	setp.lt.s32 	%p15, %r79, %r27;
	@%p15 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_12;

$L__BB0_4:
	mov.f32 	%f140, 0f00000000;

$L__BB0_12:
	mov.u32 	%r76, %ntid.x;
	mul.wide.s32 	%rd75, %r14, 4;
	add.s64 	%rd76, %rd16, %rd75;
	st.global.f32 	[%rd76], %f140;
	add.s32 	%r78, %r78, %r76;
	setp.lt.s32 	%p16, %r78, %r3;
	@%p16 bra 	$L__BB0_3;

$L__BB0_13:
	ret;

}
	// .globl	K5
.visible .entry K5(
	.param .u64 K5_param_0,
	.param .u64 K5_param_1,
	.param .u64 K5_param_2,
	.param .u64 K5_param_3,
	.param .u64 K5_param_4,
	.param .u64 K5_param_5,
	.param .u64 K5_param_6,
	.param .u32 K5_param_7,
	.param .u32 K5_param_8,
	.param .u32 K5_param_9,
	.param .u32 K5_param_10,
	.param .u32 K5_param_11
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<54>;
	.reg .b32 	%r<73>;
	.reg .b64 	%rd<78>;


	ld.param.u64 	%rd26, [K5_param_0];
	ld.param.u64 	%rd21, [K5_param_1];
	ld.param.u64 	%rd27, [K5_param_2];
	ld.param.u64 	%rd22, [K5_param_3];
	ld.param.u64 	%rd23, [K5_param_4];
	ld.param.u64 	%rd24, [K5_param_5];
	ld.param.u64 	%rd25, [K5_param_6];
	ld.param.u32 	%r23, [K5_param_7];
	ld.param.u32 	%r20, [K5_param_8];
	ld.param.u32 	%r21, [K5_param_9];
	ld.param.u32 	%r22, [K5_param_10];
	ld.param.u32 	%r24, [K5_param_11];
	cvta.to.global.u64 	%rd1, %rd27;
	cvta.to.global.u64 	%rd2, %rd26;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	div.u32 	%r26, %r1, %r22;
	mad.lo.s32 	%r2, %r25, %r24, %r26;
	setp.ge.s32 	%p1, %r2, %r23;
	@%p1 bra 	$L__BB1_12;

	mul.lo.s32 	%r3, %r21, %r20;
	mul.wide.s32 	%rd30, %r2, 4;
	add.s64 	%rd28, %rd23, %rd30;
	// begin inline asm
	ld.global.nc.s32 %r27, [%rd28];
	// end inline asm
	add.s64 	%rd29, %rd28, 4;
	// begin inline asm
	ld.global.nc.s32 %r28, [%rd29];
	// end inline asm
	rem.u32 	%r70, %r1, %r22;
	setp.ge.s32 	%p2, %r70, %r3;
	@%p2 bra 	$L__BB1_12;

	shl.b32 	%r7, %r2, 1;
	mov.u32 	%r8, %ntid.x;
	not.b32 	%r29, %r27;
	add.s32 	%r9, %r28, %r29;
	sub.s32 	%r30, %r28, %r27;
	and.b32  	%r10, %r30, 3;
	mul.wide.s32 	%rd31, %r27, 4;
	add.s64 	%rd3, %rd25, %rd31;
	add.s64 	%rd4, %rd24, %rd31;
	add.s32 	%r11, %r27, 1;
	add.s64 	%rd5, %rd3, 4;
	add.s64 	%rd6, %rd4, 4;
	add.s32 	%r12, %r27, 2;
	add.s64 	%rd7, %rd3, 8;
	add.s64 	%rd8, %rd4, 8;
	add.s32 	%r13, %r27, 3;
	add.s64 	%rd9, %rd24, 12;
	add.s64 	%rd10, %rd24, 8;
	add.s64 	%rd11, %rd24, 4;
	add.s64 	%rd12, %rd25, 12;
	add.s64 	%rd13, %rd25, 8;
	add.s64 	%rd14, %rd25, 4;
	cvta.to.global.u64 	%rd15, %rd21;
	cvta.to.global.u64 	%rd16, %rd22;

$L__BB1_3:
	shr.u32 	%r31, %r70, 31;
	add.s32 	%r32, %r70, %r31;
	shr.s32 	%r15, %r32, 1;
	setp.le.s32 	%p3, %r28, %r27;
	mov.f32 	%f53, 0f00000000;
	@%p3 bra 	$L__BB1_11;

	setp.eq.s32 	%p4, %r10, 0;
	add.s32 	%r33, %r15, %r2;
	mul.wide.s32 	%rd32, %r33, 4;
	add.s64 	%rd17, %rd15, %rd32;
	mov.f32 	%f53, 0f00000000;
	mov.u32 	%r71, %r27;
	@%p4 bra 	$L__BB1_8;

	setp.eq.s32 	%p5, %r10, 1;
	// begin inline asm
	ld.global.nc.s32 %r34, [%rd3];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r35, [%rd4];
	// end inline asm
	shl.b32 	%r36, %r34, 1;
	add.s32 	%r37, %r36, %r70;
	add.s32 	%r38, %r35, %r15;
	mul.wide.s32 	%rd35, %r38, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.f32 	%f12, [%rd17];
	ld.global.f32 	%f13, [%rd36];
	div.rn.f32 	%f14, %f13, %f12;
	mul.wide.s32 	%rd37, %r37, 4;
	add.s64 	%rd38, %rd1, %rd37;
	ld.global.f32 	%f15, [%rd38];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f53, %f16, 0f00000000;
	mov.u32 	%r71, %r11;
	@%p5 bra 	$L__BB1_8;

	setp.eq.s32 	%p6, %r10, 2;
	// begin inline asm
	ld.global.nc.s32 %r39, [%rd5];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r40, [%rd6];
	// end inline asm
	shl.b32 	%r41, %r39, 1;
	add.s32 	%r42, %r41, %r70;
	add.s32 	%r43, %r40, %r15;
	mul.wide.s32 	%rd41, %r43, 4;
	add.s64 	%rd42, %rd2, %rd41;
	ld.global.f32 	%f17, [%rd17];
	ld.global.f32 	%f18, [%rd42];
	div.rn.f32 	%f19, %f18, %f17;
	mul.wide.s32 	%rd43, %r42, 4;
	add.s64 	%rd44, %rd1, %rd43;
	ld.global.f32 	%f20, [%rd44];
	mul.rn.f32 	%f21, %f19, %f20;
	add.rn.f32 	%f53, %f53, %f21;
	mov.u32 	%r71, %r12;
	@%p6 bra 	$L__BB1_8;

	// begin inline asm
	ld.global.nc.s32 %r44, [%rd7];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r45, [%rd8];
	// end inline asm
	shl.b32 	%r46, %r44, 1;
	add.s32 	%r47, %r46, %r70;
	add.s32 	%r48, %r45, %r15;
	mul.wide.s32 	%rd47, %r48, 4;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.f32 	%f22, [%rd17];
	ld.global.f32 	%f23, [%rd48];
	div.rn.f32 	%f24, %f23, %f22;
	mul.wide.s32 	%rd49, %r47, 4;
	add.s64 	%rd50, %rd1, %rd49;
	ld.global.f32 	%f25, [%rd50];
	mul.rn.f32 	%f26, %f24, %f25;
	add.rn.f32 	%f53, %f53, %f26;
	mov.u32 	%r71, %r13;

$L__BB1_8:
	setp.lt.u32 	%p7, %r9, 3;
	@%p7 bra 	$L__BB1_11;

	mul.wide.s32 	%rd77, %r71, 4;

$L__BB1_10:
	add.s64 	%rd51, %rd25, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r49, [%rd51];
	// end inline asm
	add.s64 	%rd52, %rd24, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r50, [%rd52];
	// end inline asm
	shl.b32 	%r57, %r49, 1;
	add.s32 	%r58, %r57, %r70;
	add.s32 	%r59, %r50, %r15;
	mul.wide.s32 	%rd59, %r59, 4;
	add.s64 	%rd60, %rd2, %rd59;
	ld.global.f32 	%f27, [%rd17];
	ld.global.f32 	%f28, [%rd60];
	div.rn.f32 	%f29, %f28, %f27;
	mul.wide.s32 	%rd61, %r58, 4;
	add.s64 	%rd62, %rd1, %rd61;
	ld.global.f32 	%f30, [%rd62];
	mul.rn.f32 	%f31, %f29, %f30;
	add.rn.f32 	%f32, %f53, %f31;
	add.s64 	%rd53, %rd14, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r51, [%rd53];
	// end inline asm
	add.s64 	%rd54, %rd11, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r52, [%rd54];
	// end inline asm
	shl.b32 	%r60, %r51, 1;
	add.s32 	%r61, %r60, %r70;
	add.s32 	%r62, %r52, %r15;
	mul.wide.s32 	%rd63, %r62, 4;
	add.s64 	%rd64, %rd2, %rd63;
	ld.global.f32 	%f33, [%rd17];
	ld.global.f32 	%f34, [%rd64];
	div.rn.f32 	%f35, %f34, %f33;
	mul.wide.s32 	%rd65, %r61, 4;
	add.s64 	%rd66, %rd1, %rd65;
	ld.global.f32 	%f36, [%rd66];
	mul.rn.f32 	%f37, %f35, %f36;
	add.rn.f32 	%f38, %f32, %f37;
	add.s64 	%rd55, %rd13, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r53, [%rd55];
	// end inline asm
	add.s64 	%rd56, %rd10, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r54, [%rd56];
	// end inline asm
	shl.b32 	%r63, %r53, 1;
	add.s32 	%r64, %r63, %r70;
	add.s32 	%r65, %r54, %r15;
	mul.wide.s32 	%rd67, %r65, 4;
	add.s64 	%rd68, %rd2, %rd67;
	ld.global.f32 	%f39, [%rd17];
	ld.global.f32 	%f40, [%rd68];
	div.rn.f32 	%f41, %f40, %f39;
	mul.wide.s32 	%rd69, %r64, 4;
	add.s64 	%rd70, %rd1, %rd69;
	ld.global.f32 	%f42, [%rd70];
	mul.rn.f32 	%f43, %f41, %f42;
	add.rn.f32 	%f44, %f38, %f43;
	add.s64 	%rd57, %rd12, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r55, [%rd57];
	// end inline asm
	add.s64 	%rd58, %rd9, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r56, [%rd58];
	// end inline asm
	shl.b32 	%r66, %r55, 1;
	add.s32 	%r67, %r66, %r70;
	add.s32 	%r68, %r56, %r15;
	mul.wide.s32 	%rd71, %r68, 4;
	add.s64 	%rd72, %rd2, %rd71;
	ld.global.f32 	%f45, [%rd17];
	ld.global.f32 	%f46, [%rd72];
	div.rn.f32 	%f47, %f46, %f45;
	mul.wide.s32 	%rd73, %r67, 4;
	add.s64 	%rd74, %rd1, %rd73;
	ld.global.f32 	%f48, [%rd74];
	mul.rn.f32 	%f49, %f47, %f48;
	add.rn.f32 	%f53, %f44, %f49;
	add.s64 	%rd77, %rd77, 16;
	add.s32 	%r71, %r71, 4;
	setp.lt.s32 	%p8, %r71, %r28;
	@%p8 bra 	$L__BB1_10;

$L__BB1_11:
	add.s32 	%r69, %r70, %r7;
	mul.wide.s32 	%rd75, %r69, 4;
	add.s64 	%rd76, %rd16, %rd75;
	st.global.f32 	[%rd76], %f53;
	add.s32 	%r70, %r70, %r8;
	setp.lt.s32 	%p9, %r70, %r3;
	@%p9 bra 	$L__BB1_3;

$L__BB1_12:
	ret;

}
	// .globl	K6
.visible .entry K6(
	.param .u64 K6_param_0,
	.param .u64 K6_param_1,
	.param .u64 K6_param_2,
	.param .u64 K6_param_3,
	.param .u64 K6_param_4,
	.param .u64 K6_param_5,
	.param .u64 K6_param_6,
	.param .u64 K6_param_7,
	.param .u64 K6_param_8,
	.param .u64 K6_param_9,
	.param .u64 K6_param_10,
	.param .u64 K6_param_11,
	.param .u64 K6_param_12,
	.param .u32 K6_param_13,
	.param .u32 K6_param_14,
	.param .u32 K6_param_15,
	.param .u32 K6_param_16,
	.param .u32 K6_param_17
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<89>;
	.reg .b32 	%r<52>;
	.reg .b64 	%rd<80>;


	ld.param.u64 	%rd28, [K6_param_0];
	ld.param.u64 	%rd29, [K6_param_1];
	ld.param.u64 	%rd30, [K6_param_2];
	ld.param.u64 	%rd31, [K6_param_3];
	ld.param.u64 	%rd21, [K6_param_4];
	ld.param.u64 	%rd32, [K6_param_5];
	ld.param.u64 	%rd22, [K6_param_6];
	ld.param.u64 	%rd23, [K6_param_7];
	ld.param.u64 	%rd24, [K6_param_8];
	ld.param.u64 	%rd33, [K6_param_9];
	ld.param.u64 	%rd25, [K6_param_10];
	ld.param.u64 	%rd26, [K6_param_11];
	ld.param.u64 	%rd27, [K6_param_12];
	ld.param.u32 	%r22, [K6_param_13];
	ld.param.u32 	%r19, [K6_param_14];
	ld.param.u32 	%r20, [K6_param_15];
	ld.param.u32 	%r21, [K6_param_16];
	ld.param.u32 	%r23, [K6_param_17];
	cvta.to.global.u64 	%rd1, %rd33;
	cvta.to.global.u64 	%rd2, %rd30;
	cvta.to.global.u64 	%rd3, %rd32;
	cvta.to.global.u64 	%rd4, %rd31;
	cvta.to.global.u64 	%rd5, %rd29;
	cvta.to.global.u64 	%rd6, %rd28;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	div.u32 	%r25, %r1, %r21;
	mad.lo.s32 	%r2, %r24, %r23, %r25;
	setp.ge.s32 	%p1, %r2, %r22;
	@%p1 bra 	$L__BB2_11;

	mul.lo.s32 	%r3, %r20, %r19;
	mul.wide.s32 	%rd36, %r2, 4;
	add.s64 	%rd34, %rd25, %rd36;
	// begin inline asm
	ld.global.nc.s32 %r26, [%rd34];
	// end inline asm
	add.s64 	%rd35, %rd34, 4;
	// begin inline asm
	ld.global.nc.s32 %r27, [%rd35];
	// end inline asm
	rem.u32 	%r49, %r1, %r21;
	setp.ge.s32 	%p2, %r49, %r3;
	@%p2 bra 	$L__BB2_11;

	shl.b32 	%r7, %r2, 1;
	mov.u32 	%r8, %ntid.x;
	sub.s32 	%r28, %r27, %r26;
	and.b32  	%r9, %r28, 1;
	add.s32 	%r10, %r26, 1;
	mul.wide.s32 	%rd37, %r26, 4;
	add.s64 	%rd7, %rd27, %rd37;
	add.s64 	%rd8, %rd26, %rd37;
	cvta.to.global.u64 	%rd9, %rd22;
	cvta.to.global.u64 	%rd10, %rd21;
	cvta.to.global.u64 	%rd11, %rd23;
	cvta.to.global.u64 	%rd12, %rd24;

$L__BB2_3:
	shr.u32 	%r29, %r49, 31;
	add.s32 	%r30, %r49, %r29;
	shr.s32 	%r12, %r30, 1;
	add.s32 	%r13, %r12, %r2;
	add.s32 	%r14, %r49, %r7;
	setp.gt.s32 	%p3, %r27, %r26;
	@%p3 bra 	$L__BB2_5;
	bra.uni 	$L__BB2_4;

$L__BB2_5:
	setp.eq.s32 	%p4, %r9, 0;
	mul.wide.s32 	%rd38, %r13, 4;
	add.s64 	%rd13, %rd10, %rd38;
	mul.wide.s32 	%rd39, %r14, 4;
	add.s64 	%rd14, %rd9, %rd39;
	mov.f32 	%f88, 0f00000000;
	mov.u32 	%r51, %r26;
	mov.f32 	%f87, %f88;
	@%p4 bra 	$L__BB2_7;

	// begin inline asm
	ld.global.nc.s32 %r31, [%rd7];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r32, [%rd8];
	// end inline asm
	add.s32 	%r33, %r31, %r12;
	shl.b32 	%r34, %r31, 1;
	add.s32 	%r35, %r34, %r49;
	add.s32 	%r36, %r32, %r12;
	mul.wide.s32 	%rd42, %r36, 4;
	add.s64 	%rd43, %rd6, %rd42;
	mul.wide.s32 	%rd44, %r33, 4;
	add.s64 	%rd45, %rd5, %rd44;
	ld.global.f32 	%f18, [%rd45];
	ld.global.f32 	%f19, [%rd43];
	div.rn.f32 	%f20, %f19, %f18;
	mul.wide.s32 	%rd46, %r35, 4;
	add.s64 	%rd47, %rd4, %rd46;
	ld.global.f32 	%f21, [%rd47];
	mul.rn.f32 	%f22, %f21, %f20;
	add.s64 	%rd48, %rd3, %rd44;
	ld.global.f32 	%f23, [%rd48];
	ld.global.f32 	%f24, [%rd13];
	add.rn.f32 	%f25, %f24, %f23;
	ld.global.f32 	%f26, [%rd14];
	mul.rn.f32 	%f27, %f21, %f26;
	rcp.rn.f32 	%f28, %f18;
	mul.rn.f32 	%f29, %f27, %f28;
	div.rn.f32 	%f30, %f21, %f18;
	add.s64 	%rd49, %rd2, %rd46;
	ld.global.f32 	%f31, [%rd49];
	mul.rn.f32 	%f32, %f30, %f31;
	sub.rn.f32 	%f33, %f29, %f32;
	mul.rn.f32 	%f34, %f19, %f33;
	setp.gt.f32 	%p5, %f25, 0f00000000;
	selp.f32 	%f35, 0f3F800000, 0f3E4CCCCD, %p5;
	mul.rn.f32 	%f36, %f35, %f34;
	add.rn.f32 	%f87, %f36, 0f00000000;
	add.s64 	%rd50, %rd1, %rd44;
	atom.global.add.f32 	%f37, [%rd50], %f36;
	add.rn.f32 	%f88, %f22, 0f00000000;
	mov.u32 	%r51, %r10;

$L__BB2_7:
	setp.eq.s32 	%p6, %r27, %r10;
	@%p6 bra 	$L__BB2_10;

	mul.wide.s32 	%rd51, %r51, 4;
	add.s64 	%rd79, %rd26, %rd51;
	add.s64 	%rd78, %rd27, %rd51;

$L__BB2_9:
	// begin inline asm
	ld.global.nc.s32 %r37, [%rd78];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r38, [%rd79];
	// end inline asm
	add.s32 	%r41, %r37, %r12;
	shl.b32 	%r42, %r37, 1;
	add.s32 	%r43, %r42, %r49;
	add.s32 	%r44, %r38, %r12;
	mul.wide.s32 	%rd56, %r44, 4;
	add.s64 	%rd57, %rd6, %rd56;
	mul.wide.s32 	%rd58, %r41, 4;
	add.s64 	%rd59, %rd5, %rd58;
	ld.global.f32 	%f38, [%rd59];
	ld.global.f32 	%f39, [%rd57];
	div.rn.f32 	%f40, %f39, %f38;
	mul.wide.s32 	%rd60, %r43, 4;
	add.s64 	%rd61, %rd4, %rd60;
	ld.global.f32 	%f41, [%rd61];
	mul.rn.f32 	%f42, %f41, %f40;
	add.s64 	%rd62, %rd3, %rd58;
	ld.global.f32 	%f43, [%rd62];
	ld.global.f32 	%f44, [%rd13];
	add.rn.f32 	%f45, %f44, %f43;
	ld.global.f32 	%f46, [%rd14];
	mul.rn.f32 	%f47, %f41, %f46;
	rcp.rn.f32 	%f48, %f38;
	mul.rn.f32 	%f49, %f47, %f48;
	div.rn.f32 	%f50, %f41, %f38;
	add.s64 	%rd63, %rd2, %rd60;
	ld.global.f32 	%f51, [%rd63];
	mul.rn.f32 	%f52, %f50, %f51;
	sub.rn.f32 	%f53, %f49, %f52;
	mul.rn.f32 	%f54, %f39, %f53;
	setp.gt.f32 	%p7, %f45, 0f00000000;
	selp.f32 	%f55, 0f3F800000, 0f3E4CCCCD, %p7;
	mul.rn.f32 	%f56, %f55, %f54;
	add.rn.f32 	%f57, %f87, %f56;
	add.s64 	%rd64, %rd1, %rd58;
	atom.global.add.f32 	%f58, [%rd64], %f56;
	add.rn.f32 	%f59, %f88, %f42;
	add.s64 	%rd54, %rd78, 4;
	// begin inline asm
	ld.global.nc.s32 %r39, [%rd54];
	// end inline asm
	add.s64 	%rd55, %rd79, 4;
	// begin inline asm
	ld.global.nc.s32 %r40, [%rd55];
	// end inline asm
	add.s32 	%r45, %r39, %r12;
	shl.b32 	%r46, %r39, 1;
	add.s32 	%r47, %r46, %r49;
	add.s32 	%r48, %r40, %r12;
	mul.wide.s32 	%rd65, %r48, 4;
	add.s64 	%rd66, %rd6, %rd65;
	mul.wide.s32 	%rd67, %r45, 4;
	add.s64 	%rd68, %rd5, %rd67;
	ld.global.f32 	%f60, [%rd68];
	ld.global.f32 	%f61, [%rd66];
	div.rn.f32 	%f62, %f61, %f60;
	mul.wide.s32 	%rd69, %r47, 4;
	add.s64 	%rd70, %rd4, %rd69;
	ld.global.f32 	%f63, [%rd70];
	mul.rn.f32 	%f64, %f63, %f62;
	add.s64 	%rd71, %rd3, %rd67;
	ld.global.f32 	%f65, [%rd71];
	ld.global.f32 	%f66, [%rd13];
	add.rn.f32 	%f67, %f66, %f65;
	ld.global.f32 	%f68, [%rd14];
	mul.rn.f32 	%f69, %f63, %f68;
	rcp.rn.f32 	%f70, %f60;
	mul.rn.f32 	%f71, %f69, %f70;
	div.rn.f32 	%f72, %f63, %f60;
	add.s64 	%rd72, %rd2, %rd69;
	ld.global.f32 	%f73, [%rd72];
	mul.rn.f32 	%f74, %f72, %f73;
	sub.rn.f32 	%f75, %f71, %f74;
	mul.rn.f32 	%f76, %f61, %f75;
	setp.gt.f32 	%p8, %f67, 0f00000000;
	selp.f32 	%f77, 0f3F800000, 0f3E4CCCCD, %p8;
	mul.rn.f32 	%f78, %f77, %f76;
	add.rn.f32 	%f87, %f57, %f78;
	add.s64 	%rd73, %rd1, %rd67;
	atom.global.add.f32 	%f79, [%rd73], %f78;
	add.rn.f32 	%f88, %f59, %f64;
	add.s64 	%rd79, %rd79, 8;
	add.s64 	%rd78, %rd78, 8;
	add.s32 	%r51, %r51, 2;
	setp.lt.s32 	%p9, %r51, %r27;
	@%p9 bra 	$L__BB2_9;
	bra.uni 	$L__BB2_10;

$L__BB2_4:
	mov.f32 	%f87, 0f00000000;
	mov.f32 	%f88, %f87;

$L__BB2_10:
	mul.wide.s32 	%rd74, %r13, 4;
	add.s64 	%rd75, %rd12, %rd74;
	atom.global.add.f32 	%f80, [%rd75], %f87;
	mul.wide.s32 	%rd76, %r14, 4;
	add.s64 	%rd77, %rd11, %rd76;
	st.global.f32 	[%rd77], %f88;
	add.s32 	%r49, %r49, %r8;
	setp.lt.s32 	%p10, %r49, %r3;
	@%p10 bra 	$L__BB2_3;

$L__BB2_11:
	ret;

}

 