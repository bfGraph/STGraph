//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_61
.address_size 64

	// .globl	K2
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9all_hostsE = 1;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_35_bitE = 2;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_37_bitE = 4;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_50_bitE = 8;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_52_bitE = 16;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_53_bitE = 32;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_60_bitE = 64;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_61_bitE = 128;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_62_bitE = 256;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_70_bitE = 512;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_72_bitE = 1024;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_75_bitE = 2048;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_80_bitE = 4096;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_86_bitE = 8192;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_87_bitE = 16384;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_89_bitE = 32768;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail9sm_90_bitE = 65536;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target6detail11all_devicesE = 131070;
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target7is_hostE[8] = {1, 0, 0, 0, 0, 0, 0, 0};
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target9is_deviceE[8] = {254, 255, 1, 0, 0, 0, 0, 0};
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target10any_targetE[8] = {255, 255, 1, 0, 0, 0, 0, 0};
.global .align 8 .b8 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target9no_targetE[8];
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_35E = 35;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_37E = 37;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_50E = 50;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_52E = 52;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_53E = 53;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_60E = 60;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_61E = 61;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_62E = 62;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_70E = 70;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_72E = 72;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_75E = 75;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_80E = 80;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_86E = 86;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_87E = 87;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_89E = 89;
.global .align 8 .u64 _ZN38_INTERNAL_00000000_13_egl_kernel_cu_K22nv6target5sm_90E = 90;

.visible .entry K2(
	.param .u64 K2_param_0,
	.param .u64 K2_param_1,
	.param .u64 K2_param_2,
	.param .u64 K2_param_3,
	.param .u64 K2_param_4,
	.param .u64 K2_param_5,
	.param .u64 K2_param_6,
	.param .u32 K2_param_7,
	.param .u32 K2_param_8,
	.param .u32 K2_param_9,
	.param .u32 K2_param_10,
	.param .u32 K2_param_11
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<73>;
	.reg .b64 	%rd<78>;


	ld.param.u64 	%rd25, [K2_param_0];
	ld.param.u64 	%rd20, [K2_param_1];
	ld.param.u64 	%rd26, [K2_param_2];
	ld.param.u64 	%rd21, [K2_param_3];
	ld.param.u64 	%rd22, [K2_param_4];
	ld.param.u64 	%rd23, [K2_param_5];
	ld.param.u64 	%rd24, [K2_param_6];
	ld.param.u32 	%r23, [K2_param_7];
	ld.param.u32 	%r20, [K2_param_8];
	ld.param.u32 	%r21, [K2_param_9];
	ld.param.u32 	%r22, [K2_param_10];
	ld.param.u32 	%r24, [K2_param_11];
	cvta.to.global.u64 	%rd1, %rd26;
	cvta.to.global.u64 	%rd2, %rd25;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	div.u32 	%r26, %r1, %r22;
	mad.lo.s32 	%r2, %r25, %r24, %r26;
	setp.ge.s32 	%p1, %r2, %r23;
	@%p1 bra 	$L__BB0_12;

	mul.lo.s32 	%r3, %r21, %r20;
	mul.wide.s32 	%rd29, %r2, 4;
	add.s64 	%rd27, %rd22, %rd29;
	// begin inline asm
	ld.global.nc.s32 %r27, [%rd27];
	// end inline asm
	add.s64 	%rd28, %rd27, 4;
	// begin inline asm
	ld.global.nc.s32 %r28, [%rd28];
	// end inline asm
	rem.u32 	%r70, %r1, %r22;
	setp.ge.s32 	%p2, %r70, %r3;
	@%p2 bra 	$L__BB0_12;

	shl.b32 	%r7, %r2, 1;
	mov.u32 	%r8, %ntid.x;
	not.b32 	%r29, %r27;
	add.s32 	%r9, %r28, %r29;
	sub.s32 	%r30, %r28, %r27;
	and.b32  	%r10, %r30, 3;
	mul.wide.s32 	%rd30, %r27, 4;
	add.s64 	%rd3, %rd24, %rd30;
	add.s64 	%rd4, %rd23, %rd30;
	add.s32 	%r11, %r27, 1;
	add.s64 	%rd5, %rd3, 4;
	add.s64 	%rd6, %rd4, 4;
	add.s32 	%r12, %r27, 2;
	add.s64 	%rd7, %rd3, 8;
	add.s64 	%rd8, %rd4, 8;
	add.s32 	%r13, %r27, 3;
	add.s64 	%rd9, %rd23, 12;
	add.s64 	%rd10, %rd23, 8;
	add.s64 	%rd11, %rd23, 4;
	add.s64 	%rd12, %rd24, 12;
	add.s64 	%rd13, %rd24, 8;
	add.s64 	%rd14, %rd24, 4;
	cvta.to.global.u64 	%rd15, %rd21;
	cvta.to.global.u64 	%rd16, %rd20;

$L__BB0_3:
	shr.u32 	%r31, %r70, 31;
	add.s32 	%r32, %r70, %r31;
	shr.s32 	%r15, %r32, 1;
	setp.le.s32 	%p3, %r28, %r27;
	mov.f32 	%f41, 0f00000000;
	@%p3 bra 	$L__BB0_11;

	setp.eq.s32 	%p4, %r10, 0;
	mov.f32 	%f41, 0f00000000;
	mov.u32 	%r71, %r27;
	@%p4 bra 	$L__BB0_8;

	setp.eq.s32 	%p5, %r10, 1;
	// begin inline asm
	ld.global.nc.s32 %r33, [%rd3];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r34, [%rd4];
	// end inline asm
	add.s32 	%r35, %r33, %r15;
	shl.b32 	%r36, %r33, 1;
	add.s32 	%r37, %r36, %r70;
	mul.wide.s32 	%rd33, %r37, 4;
	add.s64 	%rd34, %rd2, %rd33;
	mul.wide.s32 	%rd35, %r35, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.f32 	%f12, [%rd36];
	ld.global.f32 	%f13, [%rd34];
	mul.rn.f32 	%f14, %f13, %f12;
	add.rn.f32 	%f41, %f14, 0f00000000;
	mov.u32 	%r71, %r11;
	@%p5 bra 	$L__BB0_8;

	setp.eq.s32 	%p6, %r10, 2;
	// begin inline asm
	ld.global.nc.s32 %r38, [%rd5];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r39, [%rd6];
	// end inline asm
	add.s32 	%r40, %r38, %r15;
	shl.b32 	%r41, %r38, 1;
	add.s32 	%r42, %r41, %r70;
	mul.wide.s32 	%rd39, %r42, 4;
	add.s64 	%rd40, %rd2, %rd39;
	mul.wide.s32 	%rd41, %r40, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.global.f32 	%f15, [%rd42];
	ld.global.f32 	%f16, [%rd40];
	mul.rn.f32 	%f17, %f16, %f15;
	add.rn.f32 	%f41, %f41, %f17;
	mov.u32 	%r71, %r12;
	@%p6 bra 	$L__BB0_8;

	// begin inline asm
	ld.global.nc.s32 %r43, [%rd7];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r44, [%rd8];
	// end inline asm
	add.s32 	%r45, %r43, %r15;
	shl.b32 	%r46, %r43, 1;
	add.s32 	%r47, %r46, %r70;
	mul.wide.s32 	%rd45, %r47, 4;
	add.s64 	%rd46, %rd2, %rd45;
	mul.wide.s32 	%rd47, %r45, 4;
	add.s64 	%rd48, %rd1, %rd47;
	ld.global.f32 	%f18, [%rd48];
	ld.global.f32 	%f19, [%rd46];
	mul.rn.f32 	%f20, %f19, %f18;
	add.rn.f32 	%f41, %f41, %f20;
	mov.u32 	%r71, %r13;

$L__BB0_8:
	setp.lt.u32 	%p7, %r9, 3;
	@%p7 bra 	$L__BB0_11;

	mul.wide.s32 	%rd77, %r71, 4;

$L__BB0_10:
	add.s64 	%rd49, %rd24, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r48, [%rd49];
	// end inline asm
	add.s64 	%rd50, %rd23, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r49, [%rd50];
	// end inline asm
	add.s32 	%r56, %r48, %r15;
	shl.b32 	%r57, %r48, 1;
	add.s32 	%r58, %r57, %r70;
	mul.wide.s32 	%rd57, %r58, 4;
	add.s64 	%rd58, %rd2, %rd57;
	mul.wide.s32 	%rd59, %r56, 4;
	add.s64 	%rd60, %rd1, %rd59;
	ld.global.f32 	%f21, [%rd60];
	ld.global.f32 	%f22, [%rd58];
	mul.rn.f32 	%f23, %f22, %f21;
	add.rn.f32 	%f24, %f41, %f23;
	add.s64 	%rd51, %rd14, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r50, [%rd51];
	// end inline asm
	add.s64 	%rd52, %rd11, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r51, [%rd52];
	// end inline asm
	add.s32 	%r59, %r50, %r15;
	shl.b32 	%r60, %r50, 1;
	add.s32 	%r61, %r60, %r70;
	mul.wide.s32 	%rd61, %r61, 4;
	add.s64 	%rd62, %rd2, %rd61;
	mul.wide.s32 	%rd63, %r59, 4;
	add.s64 	%rd64, %rd1, %rd63;
	ld.global.f32 	%f25, [%rd64];
	ld.global.f32 	%f26, [%rd62];
	mul.rn.f32 	%f27, %f26, %f25;
	add.rn.f32 	%f28, %f24, %f27;
	add.s64 	%rd53, %rd13, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r52, [%rd53];
	// end inline asm
	add.s64 	%rd54, %rd10, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r53, [%rd54];
	// end inline asm
	add.s32 	%r62, %r52, %r15;
	shl.b32 	%r63, %r52, 1;
	add.s32 	%r64, %r63, %r70;
	mul.wide.s32 	%rd65, %r64, 4;
	add.s64 	%rd66, %rd2, %rd65;
	mul.wide.s32 	%rd67, %r62, 4;
	add.s64 	%rd68, %rd1, %rd67;
	ld.global.f32 	%f29, [%rd68];
	ld.global.f32 	%f30, [%rd66];
	mul.rn.f32 	%f31, %f30, %f29;
	add.rn.f32 	%f32, %f28, %f31;
	add.s64 	%rd55, %rd12, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r54, [%rd55];
	// end inline asm
	add.s64 	%rd56, %rd9, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r55, [%rd56];
	// end inline asm
	add.s32 	%r65, %r54, %r15;
	shl.b32 	%r66, %r54, 1;
	add.s32 	%r67, %r66, %r70;
	mul.wide.s32 	%rd69, %r67, 4;
	add.s64 	%rd70, %rd2, %rd69;
	mul.wide.s32 	%rd71, %r65, 4;
	add.s64 	%rd72, %rd1, %rd71;
	ld.global.f32 	%f33, [%rd72];
	ld.global.f32 	%f34, [%rd70];
	mul.rn.f32 	%f35, %f34, %f33;
	add.rn.f32 	%f41, %f32, %f35;
	add.s64 	%rd77, %rd77, 16;
	add.s32 	%r71, %r71, 4;
	setp.lt.s32 	%p8, %r71, %r28;
	@%p8 bra 	$L__BB0_10;

$L__BB0_11:
	add.s32 	%r68, %r15, %r2;
	mul.wide.s32 	%rd73, %r68, 4;
	add.s64 	%rd74, %rd16, %rd73;
	ld.global.f32 	%f36, [%rd74];
	mul.rn.f32 	%f37, %f41, %f36;
	add.s32 	%r69, %r70, %r7;
	mul.wide.s32 	%rd75, %r69, 4;
	add.s64 	%rd76, %rd15, %rd75;
	st.global.f32 	[%rd76], %f37;
	add.s32 	%r70, %r70, %r8;
	setp.lt.s32 	%p9, %r70, %r3;
	@%p9 bra 	$L__BB0_3;

$L__BB0_12:
	ret;

}
	// .globl	K3
.visible .entry K3(
	.param .u64 K3_param_0,
	.param .u64 K3_param_1,
	.param .u64 K3_param_2,
	.param .u64 K3_param_3,
	.param .u64 K3_param_4,
	.param .u64 K3_param_5,
	.param .u64 K3_param_6,
	.param .u32 K3_param_7,
	.param .u32 K3_param_8,
	.param .u32 K3_param_9,
	.param .u32 K3_param_10,
	.param .u32 K3_param_11
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<73>;
	.reg .b64 	%rd<78>;


	ld.param.u64 	%rd25, [K3_param_0];
	ld.param.u64 	%rd26, [K3_param_1];
	ld.param.u64 	%rd20, [K3_param_2];
	ld.param.u64 	%rd21, [K3_param_3];
	ld.param.u64 	%rd22, [K3_param_4];
	ld.param.u64 	%rd23, [K3_param_5];
	ld.param.u64 	%rd24, [K3_param_6];
	ld.param.u32 	%r23, [K3_param_7];
	ld.param.u32 	%r20, [K3_param_8];
	ld.param.u32 	%r21, [K3_param_9];
	ld.param.u32 	%r22, [K3_param_10];
	ld.param.u32 	%r24, [K3_param_11];
	cvta.to.global.u64 	%rd1, %rd26;
	cvta.to.global.u64 	%rd2, %rd25;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	div.u32 	%r26, %r1, %r22;
	mad.lo.s32 	%r2, %r25, %r24, %r26;
	setp.ge.s32 	%p1, %r2, %r23;
	@%p1 bra 	$L__BB1_12;

	mul.lo.s32 	%r3, %r21, %r20;
	mul.wide.s32 	%rd29, %r2, 4;
	add.s64 	%rd27, %rd22, %rd29;
	// begin inline asm
	ld.global.nc.s32 %r27, [%rd27];
	// end inline asm
	add.s64 	%rd28, %rd27, 4;
	// begin inline asm
	ld.global.nc.s32 %r28, [%rd28];
	// end inline asm
	rem.u32 	%r70, %r1, %r22;
	setp.ge.s32 	%p2, %r70, %r3;
	@%p2 bra 	$L__BB1_12;

	shl.b32 	%r7, %r2, 1;
	mov.u32 	%r8, %ntid.x;
	not.b32 	%r29, %r27;
	add.s32 	%r9, %r28, %r29;
	sub.s32 	%r30, %r28, %r27;
	and.b32  	%r10, %r30, 3;
	mul.wide.s32 	%rd30, %r27, 4;
	add.s64 	%rd3, %rd24, %rd30;
	add.s64 	%rd4, %rd23, %rd30;
	add.s32 	%r11, %r27, 1;
	add.s64 	%rd5, %rd3, 4;
	add.s64 	%rd6, %rd4, 4;
	add.s32 	%r12, %r27, 2;
	add.s64 	%rd7, %rd3, 8;
	add.s64 	%rd8, %rd4, 8;
	add.s32 	%r13, %r27, 3;
	add.s64 	%rd9, %rd23, 12;
	add.s64 	%rd10, %rd23, 8;
	add.s64 	%rd11, %rd23, 4;
	add.s64 	%rd12, %rd24, 12;
	add.s64 	%rd13, %rd24, 8;
	add.s64 	%rd14, %rd24, 4;
	cvta.to.global.u64 	%rd15, %rd21;
	cvta.to.global.u64 	%rd16, %rd20;

$L__BB1_3:
	shr.u32 	%r31, %r70, 31;
	add.s32 	%r32, %r70, %r31;
	shr.s32 	%r15, %r32, 1;
	setp.le.s32 	%p3, %r28, %r27;
	mov.f32 	%f41, 0f00000000;
	@%p3 bra 	$L__BB1_11;

	setp.eq.s32 	%p4, %r10, 0;
	mov.f32 	%f41, 0f00000000;
	mov.u32 	%r71, %r27;
	@%p4 bra 	$L__BB1_8;

	setp.eq.s32 	%p5, %r10, 1;
	// begin inline asm
	ld.global.nc.s32 %r33, [%rd3];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r34, [%rd4];
	// end inline asm
	add.s32 	%r35, %r33, %r15;
	shl.b32 	%r36, %r33, 1;
	add.s32 	%r37, %r36, %r70;
	mul.wide.s32 	%rd33, %r37, 4;
	add.s64 	%rd34, %rd2, %rd33;
	mul.wide.s32 	%rd35, %r35, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.f32 	%f12, [%rd36];
	ld.global.f32 	%f13, [%rd34];
	mul.rn.f32 	%f14, %f13, %f12;
	add.rn.f32 	%f41, %f14, 0f00000000;
	mov.u32 	%r71, %r11;
	@%p5 bra 	$L__BB1_8;

	setp.eq.s32 	%p6, %r10, 2;
	// begin inline asm
	ld.global.nc.s32 %r38, [%rd5];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r39, [%rd6];
	// end inline asm
	add.s32 	%r40, %r38, %r15;
	shl.b32 	%r41, %r38, 1;
	add.s32 	%r42, %r41, %r70;
	mul.wide.s32 	%rd39, %r42, 4;
	add.s64 	%rd40, %rd2, %rd39;
	mul.wide.s32 	%rd41, %r40, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.global.f32 	%f15, [%rd42];
	ld.global.f32 	%f16, [%rd40];
	mul.rn.f32 	%f17, %f16, %f15;
	add.rn.f32 	%f41, %f41, %f17;
	mov.u32 	%r71, %r12;
	@%p6 bra 	$L__BB1_8;

	// begin inline asm
	ld.global.nc.s32 %r43, [%rd7];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r44, [%rd8];
	// end inline asm
	add.s32 	%r45, %r43, %r15;
	shl.b32 	%r46, %r43, 1;
	add.s32 	%r47, %r46, %r70;
	mul.wide.s32 	%rd45, %r47, 4;
	add.s64 	%rd46, %rd2, %rd45;
	mul.wide.s32 	%rd47, %r45, 4;
	add.s64 	%rd48, %rd1, %rd47;
	ld.global.f32 	%f18, [%rd48];
	ld.global.f32 	%f19, [%rd46];
	mul.rn.f32 	%f20, %f19, %f18;
	add.rn.f32 	%f41, %f41, %f20;
	mov.u32 	%r71, %r13;

$L__BB1_8:
	setp.lt.u32 	%p7, %r9, 3;
	@%p7 bra 	$L__BB1_11;

	mul.wide.s32 	%rd77, %r71, 4;

$L__BB1_10:
	add.s64 	%rd49, %rd24, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r48, [%rd49];
	// end inline asm
	add.s64 	%rd50, %rd23, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r49, [%rd50];
	// end inline asm
	add.s32 	%r56, %r48, %r15;
	shl.b32 	%r57, %r48, 1;
	add.s32 	%r58, %r57, %r70;
	mul.wide.s32 	%rd57, %r58, 4;
	add.s64 	%rd58, %rd2, %rd57;
	mul.wide.s32 	%rd59, %r56, 4;
	add.s64 	%rd60, %rd1, %rd59;
	ld.global.f32 	%f21, [%rd60];
	ld.global.f32 	%f22, [%rd58];
	mul.rn.f32 	%f23, %f22, %f21;
	add.rn.f32 	%f24, %f41, %f23;
	add.s64 	%rd51, %rd14, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r50, [%rd51];
	// end inline asm
	add.s64 	%rd52, %rd11, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r51, [%rd52];
	// end inline asm
	add.s32 	%r59, %r50, %r15;
	shl.b32 	%r60, %r50, 1;
	add.s32 	%r61, %r60, %r70;
	mul.wide.s32 	%rd61, %r61, 4;
	add.s64 	%rd62, %rd2, %rd61;
	mul.wide.s32 	%rd63, %r59, 4;
	add.s64 	%rd64, %rd1, %rd63;
	ld.global.f32 	%f25, [%rd64];
	ld.global.f32 	%f26, [%rd62];
	mul.rn.f32 	%f27, %f26, %f25;
	add.rn.f32 	%f28, %f24, %f27;
	add.s64 	%rd53, %rd13, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r52, [%rd53];
	// end inline asm
	add.s64 	%rd54, %rd10, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r53, [%rd54];
	// end inline asm
	add.s32 	%r62, %r52, %r15;
	shl.b32 	%r63, %r52, 1;
	add.s32 	%r64, %r63, %r70;
	mul.wide.s32 	%rd65, %r64, 4;
	add.s64 	%rd66, %rd2, %rd65;
	mul.wide.s32 	%rd67, %r62, 4;
	add.s64 	%rd68, %rd1, %rd67;
	ld.global.f32 	%f29, [%rd68];
	ld.global.f32 	%f30, [%rd66];
	mul.rn.f32 	%f31, %f30, %f29;
	add.rn.f32 	%f32, %f28, %f31;
	add.s64 	%rd55, %rd12, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r54, [%rd55];
	// end inline asm
	add.s64 	%rd56, %rd9, %rd77;
	// begin inline asm
	ld.global.nc.s32 %r55, [%rd56];
	// end inline asm
	add.s32 	%r65, %r54, %r15;
	shl.b32 	%r66, %r54, 1;
	add.s32 	%r67, %r66, %r70;
	mul.wide.s32 	%rd69, %r67, 4;
	add.s64 	%rd70, %rd2, %rd69;
	mul.wide.s32 	%rd71, %r65, 4;
	add.s64 	%rd72, %rd1, %rd71;
	ld.global.f32 	%f33, [%rd72];
	ld.global.f32 	%f34, [%rd70];
	mul.rn.f32 	%f35, %f34, %f33;
	add.rn.f32 	%f41, %f32, %f35;
	add.s64 	%rd77, %rd77, 16;
	add.s32 	%r71, %r71, 4;
	setp.lt.s32 	%p8, %r71, %r28;
	@%p8 bra 	$L__BB1_10;

$L__BB1_11:
	add.s32 	%r68, %r15, %r2;
	mul.wide.s32 	%rd73, %r68, 4;
	add.s64 	%rd74, %rd16, %rd73;
	ld.global.f32 	%f36, [%rd74];
	mul.rn.f32 	%f37, %f41, %f36;
	add.s32 	%r69, %r70, %r7;
	mul.wide.s32 	%rd75, %r69, 4;
	add.s64 	%rd76, %rd15, %rd75;
	st.global.f32 	[%rd76], %f37;
	add.s32 	%r70, %r70, %r8;
	setp.lt.s32 	%p9, %r70, %r3;
	@%p9 bra 	$L__BB1_3;

$L__BB1_12:
	ret;

}

 